{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución: Métodos de Selección de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import (\n",
    "    VarianceThreshold, SelectKBest, f_regression, mutual_info_regression,\n",
    "    SelectPercentile, RFE, RFECV, SelectFromModel\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Configuración para visualizaciones\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Ignorar advertencias\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar y Explorar los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos_df = pd.read_csv(\"../data/fe/autos.csv\")\n",
    "\n",
    "autos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información del dataset\n",
    "autos_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "autos_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "autos_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar variables numéricas y categóricas\n",
    "num_cols = autos_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = autos_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Variables numéricas: {len(num_cols)}\")\n",
    "print(f\"Variables categóricas: {len(cat_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir variables categóricas a numéricas usando One-Hot Encoding\n",
    "autos_encoded = pd.get_dummies(autos_df, columns=cat_cols, drop_first=True)\n",
    "autos_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las variables predictoras (X) y objetivo (y)\n",
    "X = autos_encoded.drop('price', axis=1)\n",
    "y = autos_encoded['price']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Forma del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Forma del conjunto de prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar características numéricas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convertir de nuevo a DataFrame para mantener los nombres de columnas\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Métodos de Filtrado\n",
    "\n",
    "### 3.1 Eliminar Características Constantes y Cuasi-constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar características constantes\n",
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "constant_filter.fit(X_train_scaled)\n",
    "\n",
    "# Identificar características constantes\n",
    "constant_features = [feature for feature, bool_val in zip(X_train.columns, constant_filter.get_support()) if not bool_val]\n",
    "print(f\"Características constantes: {constant_features}\")\n",
    "print(f\"Número de características constantes: {len(constant_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar características cuasi-constantes (varianza < 0.01)\n",
    "quasi_constant_filter = VarianceThreshold(threshold=0.01)\n",
    "quasi_constant_filter.fit(X_train_scaled)\n",
    "\n",
    "# Identificar características cuasi-constantes\n",
    "quasi_constant_features = [feature for feature, bool_val in zip(X_train.columns, quasi_constant_filter.get_support()) if not bool_val]\n",
    "print(f\"Características cuasi-constantes: {quasi_constant_features}\")\n",
    "print(f\"Número de características cuasi-constantes: {len(quasi_constant_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar características constantes y cuasi-constantes\n",
    "X_train_no_const = X_train_scaled.drop(columns=quasi_constant_features)\n",
    "X_test_no_const = X_test_scaled.drop(columns=quasi_constant_features)\n",
    "\n",
    "print(f\"Número original de características: {X_train_scaled.shape[1]}\")\n",
    "print(f\"Número de características después de eliminar constantes y cuasi-constantes: {X_train_no_const.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Selección Univariada con SelectKBest y SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest con f_regression\n",
    "k_best_f = SelectKBest(f_regression, k=10)\n",
    "X_train_kbest_f = k_best_f.fit_transform(X_train_no_const, y_train)\n",
    "\n",
    "# Obtener las características seleccionadas\n",
    "selected_features_kbest_f = X_train_no_const.columns[k_best_f.get_support()]\n",
    "print(\"Top 10 características seleccionadas con f_regression:\")\n",
    "print(selected_features_kbest_f.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest con mutual_info_regression\n",
    "k_best_mi = SelectKBest(mutual_info_regression, k=10)\n",
    "X_train_kbest_mi = k_best_mi.fit_transform(X_train_no_const, y_train)\n",
    "\n",
    "# Obtener las características seleccionadas\n",
    "selected_features_kbest_mi = X_train_no_const.columns[k_best_mi.get_support()]\n",
    "print(\"Top 10 características seleccionadas con mutual_info_regression:\")\n",
    "print(selected_features_kbest_mi.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectPercentile con f_regression (20% superior)\n",
    "percentile_selector = SelectPercentile(f_regression, percentile=20)\n",
    "X_train_percentile = percentile_selector.fit_transform(X_train_no_const, y_train)\n",
    "\n",
    "# Obtener las características seleccionadas\n",
    "selected_features_percentile = X_train_no_const.columns[percentile_selector.get_support()]\n",
    "print(f\"Características seleccionadas en el percentil 20 superior:\")\n",
    "print(selected_features_percentile.tolist())\n",
    "print(f\"Número de características seleccionadas: {len(selected_features_percentile)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Análisis de Correlación con Mapa de Calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación\n",
    "corr_matrix = autos_df.corr(numeric_only=True)\n",
    "\n",
    "# Visualizar el mapa de calor (solo para las top 15 características más correlacionadas con el precio)\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_with_price = corr_matrix['price'].sort_values(ascending=False)[1:16]  # Excluir price mismo\n",
    "top_corr_features = correlation_with_price.index.tolist()\n",
    "\n",
    "# Crear un subset de la matriz de correlación con las características más correlacionadas\n",
    "top_corr_matrix = corr_matrix.loc[top_corr_features, top_corr_features]\n",
    "\n",
    "# Crear el mapa de calor\n",
    "sns.heatmap(top_corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Mapa de Calor de Correlación para las 15 Características Más Correlacionadas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar las 15 características más correlacionadas con el precio\n",
    "print(\"15 características más correlacionadas con el precio:\")\n",
    "for feature, corr in correlation_with_price.items():\n",
    "    print(f\"{feature}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar pares de características altamente correlacionadas entre sí\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
    "            high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "\n",
    "# Mostrar pares de características altamente correlacionadas\n",
    "print(f\"Número de pares de características altamente correlacionadas: {len(high_corr_pairs)}\")\n",
    "for feature1, feature2, corr in high_corr_pairs:\n",
    "    print(f\"{feature1} - {feature2}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar características altamente correlacionadas (manteniendo la más correlacionada con el precio)\n",
    "def remove_correlated_features(X, threshold=0.9):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Identificar características para eliminar\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    \n",
    "    # Para cada par de características correlacionadas, mantener la más correlacionada con el precio\n",
    "    price_corr = X.corrwith(y).abs()\n",
    "    features_to_keep = []\n",
    "    \n",
    "    for i in range(len(upper.columns)):\n",
    "        for j in range(i+1, len(upper.columns)):\n",
    "            col_i = upper.columns[i]\n",
    "            col_j = upper.columns[j]\n",
    "            if upper.iloc[i, j] > threshold:\n",
    "                if price_corr[col_i] > price_corr[col_j]:\n",
    "                    if col_j in to_drop and col_j not in features_to_keep:\n",
    "                        features_to_keep.append(col_i)\n",
    "                else:\n",
    "                    if col_i in to_drop and col_i not in features_to_keep:\n",
    "                        features_to_keep.append(col_j)\n",
    "    \n",
    "    # Eliminar características, pero mantener las que están en features_to_keep\n",
    "    final_to_drop = [col for col in to_drop if col not in features_to_keep]\n",
    "    \n",
    "    return X.drop(columns=final_to_drop), final_to_drop\n",
    "\n",
    "X_train_no_corr, dropped_features = remove_correlated_features(X_train_no_const)\n",
    "\n",
    "print(f\"Número de características eliminadas por alta correlación: {len(dropped_features)}\")\n",
    "print(f\"Características eliminadas: {dropped_features}\")\n",
    "print(f\"Número de características restantes: {X_train_no_corr.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Métodos Wrapper\n",
    "\n",
    "### 4.1 Eliminación Recursiva de Características (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar RFE con regresión lineal\n",
    "lm = LinearRegression()\n",
    "rfe = RFE(estimator=lm, n_features_to_select=10, step=1)\n",
    "rfe.fit(X_train_no_corr, y_train)\n",
    "\n",
    "# Obtener las características seleccionadas\n",
    "selected_features_rfe = X_train_no_corr.columns[rfe.get_support()]\n",
    "\n",
    "print(\"Características seleccionadas por RFE:\")\n",
    "print(selected_features_rfe.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo con las características seleccionadas por RFE\n",
    "X_train_rfe = X_train_no_corr[selected_features_rfe]\n",
    "X_test_rfe = X_test_scaled[selected_features_rfe]\n",
    "\n",
    "lm.fit(X_train_rfe, y_train)\n",
    "y_pred_rfe = lm.predict(X_test_rfe)\n",
    "\n",
    "rmse_rfe = np.sqrt(mean_squared_error(y_test, y_pred_rfe))\n",
    "r2_rfe = r2_score(y_test, y_pred_rfe)\n",
    "\n",
    "print(f\"RMSE con características RFE: {rmse_rfe:.2f}\")\n",
    "print(f\"R² con características RFE: {r2_rfe:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar RFECV para encontrar el número óptimo de características\n",
    "rfecv = RFECV(estimator=lm, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "rfecv.fit(X_train_no_corr, y_train)\n",
    "\n",
    "# Obtener las características seleccionadas\n",
    "selected_features_rfecv = X_train_no_corr.columns[rfecv.get_support()]\n",
    "\n",
    "print(f\"Número óptimo de características: {rfecv.n_features_}\")\n",
    "print(\"Características seleccionadas por RFECV:\")\n",
    "print(selected_features_rfecv.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo con las características seleccionadas por RFECV\n",
    "X_train_rfecv = X_train_no_corr[selected_features_rfecv]\n",
    "X_test_rfecv = X_test_scaled[selected_features_rfecv]\n",
    "\n",
    "lm.fit(X_train_rfecv, y_train)\n",
    "y_pred_rfecv = lm.predict(X_test_rfecv)\n",
    "\n",
    "rmse_rfecv = np.sqrt(mean_squared_error(y_test, y_pred_rfecv))\n",
    "r2_rfecv = r2_score(y_test, y_pred_rfecv)\n",
    "\n",
    "print(f\"RMSE con características RFECV: {rmse_rfecv:.2f}\")\n",
    "print(f\"R² con características RFECV: {r2_rfecv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Métodos Integrados\n",
    "\n",
    "### 5.1 Selección con LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar Lasso para selección de características\n",
    "lasso = Lasso(alpha=0.1)  # Ajustar alpha según sea necesario\n",
    "lasso.fit(X_train_no_corr, y_train)\n",
    "\n",
    "# Mostrar los coeficientes\n",
    "coefs = pd.Series(lasso.coef_, index=X_train_no_corr.columns)\n",
    "importance = pd.DataFrame({'Feature': X_train_no_corr.columns, 'Importance': np.abs(lasso.coef_)})\n",
    "importance = importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Visualizar las 15 características más importantes según LASSO\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance.head(15))\n",
    "plt.title('Top 15 Características Seleccionadas por LASSO')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo con las características seleccionadas por LASSO\n",
    "lm.fit(X_train_lasso, y_train)\n",
    "y_pred_lasso = lm.predict(X_test_lasso)\n",
    "\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(f\"RMSE con características LASSO: {rmse_lasso:.2f}\")\n",
    "print(f\"R² con características LASSO: {r2_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar características con coeficientes no nulos\n",
    "lasso_selector = SelectFromModel(lasso, prefit=True)\n",
    "X_train_lasso = lasso_selector.transform(X_train_no_corr)\n",
    "X_test_lasso = lasso_selector.transform(X_test_scaled[X_train_no_corr.columns])\n",
    "\n",
    "# Obtener nombres de características seleccionadas\n",
    "selected_features_lasso = X_train_no_corr.columns[lasso_selector.get_support()]\n",
    "\n",
    "print(f\"Número de características seleccionadas por LASSO: {len(selected_features_lasso)}\")\n",
    "print(\"Características seleccionadas:\")\n",
    "print(selected_features_lasso.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con diferentes valores de alpha para LASSO\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "num_features = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_no_corr, y_train)\n",
    "    \n",
    "    # Contar características no nulas\n",
    "    n_features = sum(lasso.coef_ != 0)\n",
    "    num_features.append(n_features)\n",
    "    \n",
    "    # Evaluar en el conjunto de prueba\n",
    "    y_pred = lasso.predict(X_test_scaled[X_train_no_corr.columns])\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    rmse_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "    \n",
    "    print(f\"Alpha: {alpha}, # Features: {n_features}, RMSE: {rmse:.2f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el efecto de alpha en LASSO\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogx(alphas, rmse_scores, marker='o')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE vs Alpha')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogx(alphas, num_features, marker='o')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Número de Características')\n",
    "plt.title('Número de Características vs Alpha')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparación de Modelos y Conclusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar todos los métodos de selección de características\n",
    "models = {\n",
    "    'RFE (10 feat.)': {'features': selected_features_rfe, 'rmse': rmse_rfe, 'r2': r2_rfe},\n",
    "    'RFECV': {'features': selected_features_rfecv, 'rmse': rmse_rfecv, 'r2': r2_rfecv},\n",
    "    'LASSO': {'features': selected_features_lasso.tolist(), 'rmse': rmse_lasso, 'r2': r2_lasso}\n",
    "}\n",
    "\n",
    "# Entrenar modelo con todas las características disponibles (después de eliminar correlacionadas)\n",
    "lm.fit(X_train_no_corr, y_train)\n",
    "y_pred_all = lm.predict(X_test_scaled[X_train_no_corr.columns])\n",
    "rmse_all = np.sqrt(mean_squared_error(y_test, y_pred_all))\n",
    "r2_all = r2_score(y_test, y_pred_all)\n",
    "\n",
    "models['Todas las características'] = {\n",
    "    'features': X_train_no_corr.columns.tolist(), \n",
    "    'rmse': rmse_all, \n",
    "    'r2': r2_all\n",
    "}\n",
    "\n",
    "# Crear un DataFrame para comparar resultados\n",
    "comparison = pd.DataFrame({\n",
    "    'Método': list(models.keys()),\n",
    "    'Número de Características': [len(model['features']) for model in models.values()],\n",
    "    'RMSE': [model['rmse'] for model in models.values()],\n",
    "    'R²': [model['r2'] for model in models.values()]\n",
    "})\n",
    "\n",
    "comparison.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la comparación\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.barplot(x='Método', y='RMSE', data=comparison)\n",
    "plt.title('RMSE por Método de Selección de Características')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.barplot(x='Método', y='Número de Características', data=comparison)\n",
    "plt.title('Número de Características por Método de Selección')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Características Finales Seleccionadas\n",
    "\n",
    "Basado en los resultados anteriores, seleccionamos el conjunto de características del método que dio el mejor balance entre rendimiento (RMSE/R²) y simplicidad (número de características)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinar el mejor método (en este caso asumimos que es RFECV)\n",
    "best_method = 'LASSO'\n",
    "best_features = models[best_method]['features']\n",
    "\n",
    "print(f\"Método seleccionado: {best_method}\")\n",
    "print(f\"Número de características: {len(best_features)}\")\n",
    "print(f\"RMSE: {models[best_method]['rmse']:.2f}\")\n",
    "print(f\"R²: {models[best_method]['r2']:.4f}\")\n",
    "print(\"\\nCaracterísticas seleccionadas:\")\n",
    "for feature in best_features:\n",
    "    print(f\"- {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar la lista de características seleccionadas\n",
    "selected_features_df = pd.DataFrame({'feature': best_features})\n",
    "\n",
    "selected_features_df.to_csv('selected_features.csv', index=False)\n",
    "\n",
    "# Guardar también el dataset con solo las características seleccionadas\n",
    "final_df = autos_df.copy()\n",
    "final_df = pd.get_dummies(final_df, columns=cat_cols, drop_first=True)\n",
    "final_df = final_df[list(best_features) + ['price']]\n",
    "final_df.to_csv('autos_selected_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
