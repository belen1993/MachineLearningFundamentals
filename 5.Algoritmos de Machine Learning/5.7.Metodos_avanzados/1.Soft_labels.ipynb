{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Soft Labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué son los Soft Labels?\n",
    "Los **soft labels** (etiquetas suaves) son probabilidades asociadas a cada clase frente a etiquetas duras (hard labels). \n",
    "- En lugar de asignar una clase específica (por ejemplo, `0` o `1`), las soft labels representan la probabilidad de pertenencia de una muestra a cada clase.\n",
    "\n",
    "Por ejemplo:\n",
    "- Hard label: `[0]` (la muestra pertenece a la clase 0).\n",
    "- Soft label: `[0.8, 0.2]` (la muestra tiene un 80% de probabilidad de pertenecer a la clase 0 y un 20% de pertenecer a la clase 1).\n",
    "\n",
    "### ¿Por qué usar Soft Labels?\n",
    "1. **Incorporación de incertidumbre**: Las soft labels permiten modelar la incertidumbre en las etiquetas.\n",
    "2. **Mejora en el entrenamiento**: Algunos modelos pueden beneficiarse de soft labels para aprender patrones más robustos.\n",
    "3. **Transferencia de conocimiento**: En aprendizaje por transferencia, las soft labels generadas por un modelo maestro pueden usarse para entrenar un modelo estudiante (técnica conocida como *knowledge distillation*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ejemplo Práctico con Scikit-Learn\n",
    "\n",
    "En este ejemplo, generaremos datos sintéticos y usaremos soft labels para entrenar un modelo de regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/titanic/train.csv')\n",
    "df.columns\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['PassengerId', 'Survived', 'Pclass', 'Name',\n",
    "            'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], axis=1)\n",
    "\n",
    "y = df['Survived']\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenc = LabelEncoder()\n",
    "stadscl = StandardScaler()\n",
    "\n",
    "X['Sex'] = lenc.fit_transform(X['Sex'])\n",
    "X = stadscl.fit_transform(X)\n",
    "\n",
    "print('X:', X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador clásico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model = LogisticRegression(random_state=42)\n",
    "class_model.fit(X_train, y_train)\n",
    "\n",
    "# Generar soft labels usando predict_proba: devuelve la estimación de probabilidad\n",
    "y_pred = class_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear Soft Labels\n",
    "Generamos soft labels simulando probabilidades para cada clase. Usaremos un modelo maestro (en este caso, también una regresión logística) para generar estas probabilidades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar un modelo maestro para generar soft labels\n",
    "master_model = LogisticRegression(random_state=42)\n",
    "master_model.fit(X_train, y_train)\n",
    "\n",
    "# Generar soft labels usando predict_proba: devuelve la estimación de probabilidad\n",
    "soft_labels_train = master_model.predict_proba(X_train)\n",
    "\n",
    "# Mostrar las primeras 5 soft labels\n",
    "print(\"Soft Labels (primeras 5 filas):\")\n",
    "print(soft_labels_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar un Modelo Estudiante con Soft Labels\n",
    "Usamos las soft labels generadas para entrenar un modelo lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar un modelo con soft labels\n",
    "reg_model = LinearRegression()\n",
    "# Usamos la probabilidad de la clase 1\n",
    "reg_model.fit(X_train, soft_labels_train[:, 1])\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = reg_model.predict(X_test)\n",
    "print(y_pred)\n",
    "y_pred_proba = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Evaluar el rendimiento\n",
    "accuracy = accuracy_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resultados y Conclusión\n",
    "\n",
    "### Resultados\n",
    "- El modelo estudiante se entrena con soft labels generadas por el modelo maestro.\n",
    "- Las soft labels permiten al modelo estudiante aprender patrones más suaves y generalizables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "- Los soft labels son útiles para incorporar incertidumbre en el proceso de entrenamiento.\n",
    "- Técnicas como *knowledge distillation* utilizan soft labels para transferir conocimiento de un modelo grande a uno más pequeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio:\n",
    "1. Entrenar un modelo de forecasting para predecir predecir si el consumo de combustible subirá o bajar a 12 meses vista usando sof labels.\n",
    "\n",
    "- Usa el dataset 'fuel_consumption'.\n",
    "- Usa frecuancia mensual.\n",
    "\n",
    "ref. https://github.com/skforecast/skforecast-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuel_consumption\n",
      "----------------\n",
      "Monthly fuel consumption in Spain from 1969-01-01 to 2022-08-01.\n",
      "Obtained from Corporación de Reservas Estratégicas de Productos Petrolíferos and\n",
      "Corporación de Derecho Público tutelada por el Ministerio para la Transición\n",
      "Ecológica y el Reto Demográfico. https://www.cores.es/es/estadisticas\n",
      "Shape of the dataset: (644, 5)\n",
      "+---------------------+----------+-------------+--------------+------------+------------------+----------+\n",
      "| Fecha               |     GLPs |   Gasolinas |   Querosenos |   Gasoleos |        Fueloleos |   target |\n",
      "|---------------------+----------+-------------+--------------+------------+------------------+----------|\n",
      "| 1969-01-01 00:00:00 | 133615   |      166875 |       123258 |     401185 | 912583           |        0 |\n",
      "| 1969-02-01 00:00:00 | 126748   |      155467 |       114683 |     385360 | 851878           |        0 |\n",
      "| 1969-03-01 00:00:00 | 107796   |      184984 |       109970 |     418956 | 873884           |        0 |\n",
      "| 1969-04-01 00:00:00 |  96683.2 |      202320 |       108798 |     438976 | 755490           |        0 |\n",
      "| 1969-05-01 00:00:00 |  79506.2 |      206259 |       103554 |     467452 | 729964           |        0 |\n",
      "| 1969-06-01 00:00:00 |  72091.2 |      208412 |       104792 |     463566 | 655314           |        0 |\n",
      "| 1969-07-01 00:00:00 |  72515.2 |      265737 |       109992 |     503947 | 703709           |        1 |\n",
      "| 1969-08-01 00:00:00 |  69601.3 |      282287 |       108587 |     493495 | 757296           |        0 |\n",
      "| 1969-09-01 00:00:00 |  80101.3 |      232226 |       109206 |     474779 | 813478           |        1 |\n",
      "| 1969-10-01 00:00:00 |  90848   |      217134 |       109146 |     493100 | 824577           |        1 |\n",
      "| 1969-11-01 00:00:00 | 115474   |      184276 |       112432 |     451288 | 868227           |        1 |\n",
      "| 1969-12-01 00:00:00 | 168441   |      210768 |       135401 |     439303 |      1.08132e+06 |        1 |\n",
      "| 1970-01-01 00:00:00 | 151271   |      191248 |       131476 |     423391 |      1.03584e+06 |        0 |\n",
      "| 1970-02-01 00:00:00 | 127157   |      186341 |       124061 |     433168 | 876489           |        0 |\n",
      "| 1970-03-01 00:00:00 | 137593   |      224118 |       137310 |     476572 | 927792           |        1 |\n",
      "| 1970-04-01 00:00:00 | 109806   |      223822 |       139170 |     502526 |      1.00026e+06 |        0 |\n",
      "| 1970-05-01 00:00:00 |  89821.7 |      231714 |       149087 |     476165 | 913753           |        0 |\n",
      "| 1970-06-01 00:00:00 |  77227.7 |      244820 |       157043 |     509821 | 799807           |        0 |\n",
      "| 1970-07-01 00:00:00 |  82506.2 |      307764 |       164949 |     546020 | 911370           |        1 |\n",
      "| 1970-08-01 00:00:00 |  83214.3 |      326758 |       166700 |     521145 | 870753           |        1 |\n",
      "+---------------------+----------+-------------+--------------+------------+------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Cargar el dataset fuel_consumption\n",
    "data = fetch_dataset(\"fuel_consumption\")\n",
    "\n",
    "# Crear la variable objetivo: 1 si el consumo sube, 0 si baja\n",
    "data['target'] = (data['GLPs'].diff() > 0).astype(int)\n",
    "\n",
    "# Eliminar valores faltantes generados por la diferenciación\n",
    "data = data.dropna()\n",
    "\n",
    "# Mostrar los primeros registros\n",
    "print(tabulate(data.head(20),   headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              Gasolinas   Querosenos      Gasoleos    Fueloleos\n",
       " Fecha                                                          \n",
       " 1969-01-01  166875.2129  123257.8090  4.011853e+05  912583.4202\n",
       " 1969-02-01  155466.8105  114682.5767  3.853600e+05  851877.8115\n",
       " 1969-03-01  184983.6699  109970.0796  4.189556e+05  873884.2933\n",
       " 1969-04-01  202319.8164  108797.9255  4.389755e+05  755490.1170\n",
       " 1969-05-01  206259.1523  103554.0784  4.674519e+05  729963.6009\n",
       " ...                 ...          ...           ...          ...\n",
       " 2022-04-01  471601.9400  494966.3200  2.638030e+06  636930.4200\n",
       " 2022-05-01  478873.4100  530034.0100  2.673797e+06  708289.2600\n",
       " 2022-06-01  501447.1400  540594.9700  2.648087e+06  667221.4500\n",
       " 2022-07-01  534584.6800  607854.6800  2.613591e+06  691371.6000\n",
       " 2022-08-01  565761.9600  596051.0800  2.572012e+06  701384.4100\n",
       " \n",
       " [644 rows x 4 columns],\n",
       " Fecha\n",
       " 1969-01-01    0\n",
       " 1969-02-01    0\n",
       " 1969-03-01    0\n",
       " 1969-04-01    0\n",
       " 1969-05-01    0\n",
       "              ..\n",
       " 2022-04-01    0\n",
       " 2022-05-01    0\n",
       " 2022-06-01    1\n",
       " 2022-07-01    0\n",
       " 2022-08-01    0\n",
       " Freq: MS, Name: target, Length: 644, dtype: int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= data.drop(['target','GLPs'], axis=1)\n",
    "y= data['target']\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            Gasolinas  Querosenos    Gasoleos  Fueloleos\n",
       " Fecha                                                   \n",
       " 2021-04-01  377438.65   140343.00  2448229.67  505302.60\n",
       " 2021-05-01  432848.68   176393.81  2520854.77  484193.72\n",
       " 2021-06-01  483500.45   248326.60  2628985.76  508827.10\n",
       " 2021-07-01  540217.21   394659.97  2693994.26  517741.86\n",
       " 2021-08-01  540653.12   426644.89  2525759.39  578165.99,\n",
       " Fecha\n",
       " 2021-09-01    1\n",
       " 2021-10-01    1\n",
       " 2021-11-01    1\n",
       " 2021-12-01    1\n",
       " 2022-01-01    0\n",
       " Freq: MS, Name: target, dtype: int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test = X[:-12], X[-12:]\n",
    "y_train, y_test = y[:-12], y[-12:]\n",
    "\n",
    "X_train.tail(), y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Labels (primeras 5 filas):\n",
      "                  P0        P1\n",
      "Fecha                         \n",
      "1969-06-01  0.506419  0.493581\n",
      "1969-07-01  0.511182  0.488818\n",
      "1969-08-01  0.510120  0.489880\n",
      "1969-09-01  0.499918  0.500082\n",
      "1969-10-01  0.493242  0.506758\n",
      "...              ...       ...\n",
      "2021-04-01  0.279623  0.720377\n",
      "2021-05-01  0.307566  0.692434\n",
      "2021-06-01  0.357848  0.642152\n",
      "2021-07-01  0.489086  0.510914\n",
      "2021-08-01  0.540876  0.459124\n",
      "\n",
      "[627 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Entrenar un modelo maestro para generar soft labels\n",
    "master_model = LogisticRegression(random_state=42)\n",
    "master_model.fit(X_train, y_train)\n",
    "\n",
    "# Generar soft labels usando predict_proba: devuelve la estimación de probabilidad\n",
    "soft_labels_train = pd.DataFrame( master_model.predict_proba(X_train), index=X_train.index, columns=['P0', 'P1'])\n",
    "\n",
    "# Mostrar las primeras 5 soft labels\n",
    "print(\"Soft Labels (primeras 5 filas):\")\n",
    "print(soft_labels_train[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fechas train : 1969-01-01 00:00:00 --- 2021-08-01 00:00:00  (n=632)\n"
     ]
    }
   ],
   "source": [
    "# Separación datos train-test\n",
    "\n",
    "steps = 12\n",
    "datos_train = soft_labels_train\n",
    "# datos_test  = soft_labels_train[-steps:]\n",
    "\n",
    "print(f\"Fechas train : {datos_train.index.min()} --- {datos_train.index.max()}  (n={len(datos_train)})\")\n",
    "# print(f\"Fechas test  : {datos_test.index.min()} --- {datos_test.index.max()}  (n={len(datos_test)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .container-0716cf36e7d04e0295003cd12fbdedbe {\n",
       "            font-family: 'Arial', sans-serif;\n",
       "            font-size: 0.9em;\n",
       "            color: #333333;\n",
       "            border: 1px solid #ddd;\n",
       "            background-color: #f0f8ff;\n",
       "            padding: 5px 15px;\n",
       "            border-radius: 8px;\n",
       "            max-width: 600px;\n",
       "            #margin: auto;\n",
       "        }\n",
       "        .container-0716cf36e7d04e0295003cd12fbdedbe h2 {\n",
       "            font-size: 1.5em;\n",
       "            color: #222222;\n",
       "            border-bottom: 2px solid #ddd;\n",
       "            padding-bottom: 5px;\n",
       "            margin-bottom: 15px;\n",
       "            margin-top: 5px;\n",
       "        }\n",
       "        .container-0716cf36e7d04e0295003cd12fbdedbe details {\n",
       "            margin: 10px 0;\n",
       "        }\n",
       "        .container-0716cf36e7d04e0295003cd12fbdedbe summary {\n",
       "            font-weight: bold;\n",
       "            font-size: 1.1em;\n",
       "            color: #000000;\n",
       "            cursor: pointer;\n",
       "            margin-bottom: 5px;\n",
       "            background-color: #b3dbfd;\n",
       "            padding: 5px;\n",
       "            border-radius: 5px;\n",
       "        }\n",
       "        .container-0716cf36e7d04e0295003cd12fbdedbe summary:hover {\n",
       "            color: #000000;\n",
       "            background-color: #e0e0e0;\n",
       "        }\n",
       "        .container-0716cf36e7d04e0295003cd12fbdedbe ul {\n",
       "            font-family: 'Courier New', monospace;\n",
       "            list-style-type: none;\n",
       "            padding-left: 20px;\n",
       "            margin: 10px 0;\n",
       "            line-height: normal;\n",
       "        }\n",
       "        .container-0716cf36e7d04e0295003cd12fbdedbe li {\n",
       "            margin: 5px 0;\n",
       "            font-family: 'Courier New', monospace;\n",
       "        }\n",
       "        .container-0716cf36e7d04e0295003cd12fbdedbe li strong {\n",
       "            font-weight: bold;\n",
       "            color: #444444;\n",
       "        }\n",
       "        .container-0716cf36e7d04e0295003cd12fbdedbe li::before {\n",
       "            content: \"- \";\n",
       "            color: #666666;\n",
       "        }\n",
       "        .container-0716cf36e7d04e0295003cd12fbdedbe a {\n",
       "            color: #001633;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "        .container-0716cf36e7d04e0295003cd12fbdedbe a:hover {\n",
       "            color: #359ccb; \n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "        <div class=\"container-0716cf36e7d04e0295003cd12fbdedbe\">\n",
       "            <h2>ForecasterRecursive</h2>\n",
       "            <details open>\n",
       "                <summary>General Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Regressor:</strong> LinearRegression</li>\n",
       "                    <li><strong>Lags:</strong> [ 1  2  3  4  5  6  7  8  9 10 11 12]</li>\n",
       "                    <li><strong>Window features:</strong> None</li>\n",
       "                    <li><strong>Window size:</strong> 12</li>\n",
       "                    <li><strong>Exogenous included:</strong> False</li>\n",
       "                    <li><strong>Weight function included:</strong> False</li>\n",
       "                    <li><strong>Differentiation order:</strong> None</li>\n",
       "                    <li><strong>Creation date:</strong> 2025-04-10 10:00:33</li>\n",
       "                    <li><strong>Last fit date:</strong> 2025-04-10 10:00:33</li>\n",
       "                    <li><strong>Skforecast version:</strong> 0.15.1</li>\n",
       "                    <li><strong>Python version:</strong> 3.10.11</li>\n",
       "                    <li><strong>Forecaster id:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Exogenous Variables</summary>\n",
       "                <ul>\n",
       "                    None\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Data Transformations</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Transformer for y:</strong> None</li>\n",
       "                    <li><strong>Transformer for exog:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Training Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Training range:</strong> [Timestamp('1969-01-01 00:00:00'), Timestamp('2021-08-01 00:00:00')]</li>\n",
       "                    <li><strong>Training index type:</strong> DatetimeIndex</li>\n",
       "                    <li><strong>Training index frequency:</strong> MS</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Regressor Parameters</summary>\n",
       "                <ul>\n",
       "                    {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Fit Kwargs</summary>\n",
       "                <ul>\n",
       "                    {}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <p>\n",
       "                <a href=\"https://skforecast.org/0.15.1/api/forecasterrecursive.html\">&#128712 <strong>API Reference</strong></a>\n",
       "                &nbsp;&nbsp;\n",
       "                <a href=\"https://skforecast.org/0.15.1/user_guides/autoregresive-forecaster.html\">&#128462 <strong>User Guide</strong></a>\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "=================== \n",
       "ForecasterRecursive \n",
       "=================== \n",
       "Regressor: LinearRegression \n",
       "Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
       "Window features: None \n",
       "Window size: 12 \n",
       "Exogenous included: False \n",
       "Exogenous names: None \n",
       "Transformer for y: None \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Differentiation order: None \n",
       "Training range: [Timestamp('1969-01-01 00:00:00'), Timestamp('2021-08-01 00:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: MS \n",
       "Regressor parameters: \n",
       "    {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2025-04-10 10:00:33 \n",
       "Last fit date: 2025-04-10 10:00:33 \n",
       "Skforecast version: 0.15.1 \n",
       "Python version: 3.10.11 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skforecast.recursive import ForecasterRecursive\n",
    "\n",
    "# Crear el forecaster recursivo con un modelo de regresión lineal\n",
    "forecaster = ForecasterRecursive(\n",
    "    regressor=LinearRegression(),\n",
    "    lags=12  # Predecir 12 pasos hacia el futuro\n",
    ")\n",
    "\n",
    "\n",
    "forecaster.fit(y=datos_train['P1'])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021-09-01    0.498811\n",
       "2021-10-01    0.540225\n",
       "2021-11-01    0.596730\n",
       "2021-12-01    0.642612\n",
       "2022-01-01    0.694055\n",
       "2022-02-01    0.741014\n",
       "2022-03-01    0.730721\n",
       "2022-04-01    0.698947\n",
       "2022-05-01    0.667746\n",
       "2022-06-01    0.610448\n",
       "2022-07-01    0.551152\n",
       "2022-08-01    0.514837\n",
       "Freq: MS, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicciones\n",
    "\n",
    "y_pred = forecaster.predict(steps=steps)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4167\n"
     ]
    }
   ],
   "source": [
    "# Predecir en el conjunto de prueba\n",
    "y_pred_proba = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Evaluar el rendimiento\n",
    "accuracy = accuracy_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'Fecha' a índice temporal\n",
    "type(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.drop(['target'], axis=1)\n",
    "y= data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar un modelo maestro para generar soft labels\n",
    "master_model = LogisticRegression(random_state=42)\n",
    "master_model.fit(X_train, y_train)\n",
    "\n",
    "# Generar soft labels usando predict_proba: devuelve la estimación de probabilidad\n",
    "soft_labels_train = pd.DataFrame( master_model.predict_proba(X_train), index=X_train.index, columns=['P0', 'P1'])\n",
    "\n",
    "# Mostrar las primeras 5 soft labels\n",
    "print(\"Soft Labels (primeras 5 filas):\")\n",
    "print(soft_labels_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación datos train-test\n",
    "\n",
    "steps = 12\n",
    "datos_train = soft_labels_train[:-steps]\n",
    "datos_test  = soft_labels_train[-steps:]\n",
    "\n",
    "print(f\"Fechas train : {datos_train.index.min()} --- {datos_train.index.max()}  (n={len(datos_train)})\")\n",
    "print(f\"Fechas test  : {datos_test.index.min()} --- {datos_test.index.max()}  (n={len(datos_test)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.recursive import ForecasterRecursive\n",
    "\n",
    "# Crear el forecaster recursivo con un modelo de regresión lineal\n",
    "forecaster = ForecasterRecursive(\n",
    "    regressor=LinearRegression(),\n",
    "    lags=12  # Predecir 12 pasos hacia el futuro\n",
    ")\n",
    "\n",
    "\n",
    "forecaster.fit(y=datos_train['P0'])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "\n",
    "y_pred = forecaster.predict(steps=steps)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en el conjunto de prueba\n",
    "y_pred_proba = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Evaluar el rendimiento\n",
    "accuracy = accuracy_score(y_test[:12], y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
