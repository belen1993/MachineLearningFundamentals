{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducción de Dimensionalidad. PCA\n",
    "\n",
    "\n",
    "PCA es una técnica estadística introducida por el matemático Karl Pearson en 1901. \n",
    "- Funciona transformando los datos de alta dimensión en un espacio de baja dimensión (eigenvectores) a la vez que maximiza la varianza (o dispersión) de los datos en el nuevo espacio.\n",
    "- Esto ayuda a preservar los patrones y relaciones más importantes en los datos.\n",
    "- En Scikit-learn existe un componente [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "\n",
    "\"PCA = Reducir dimensiones, Preservar información\"\n",
    "\n",
    "**Saber más:** https://medium.com/all-about-ml/understanding-principal-component-analysis-pca-556778324b0e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/ricardoahumada/Python_for_Data_Science/raw/refs/heads/master/data/2008_small.zip\",nrows = 1000000)\n",
    "\n",
    "\n",
    "df = df.dropna(subset = ['AirTime','Distance','TaxiIn','TaxiOut',\"DepDelay\",\"ArrDelay\"])\n",
    "df = df.sample(frac=1).head(1000)\n",
    "\n",
    "X = df[['AirTime','Distance','TaxiIn','TaxiOut',\"DepDelay\",\"ArrDelay\"]] \n",
    "columnas = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar los datos y entrenr el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preparamos los datos y entrenamos el modelo\n",
    "scaler = StandardScaler()   ## IMPORTANTISIMO ##\n",
    "scaler.fit(X)\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entremar el modelo: el numero de componentes son la cantidad de nuevas columnas que quiero\n",
    "pca = PCA(n_components=2) \n",
    "\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del resultado: explicabilidad\n",
    "\n",
    ">La interpretación de los datos se relaciona de manera directa con las columnas originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composición de las PCAs\n",
    "pd.DataFrame(np.round(pca.components_,2),columns=columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1a componente - PCA1 : Tiene más peso DepDelay y ArrDelay en la misma dirección.\n",
    "- 2a componente - PCA2 : Tiene más peso AirTime\ty Distance en la dirección opuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicabilidad de la nueva varianza\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El PCA1 explica el 34% de la varianza\n",
    "- El PCA2 explica el 33% de la varianza\n",
    "- En conjunto explican el 69% de la varianza original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los nuevos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevosvalores = pca.transform(X)\n",
    "pd.DataFrame(nuevosvalores,columns=['PCA1', 'PCA2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la transformación del espacio\n",
    "\n",
    "plt.scatter(nuevosvalores[:,0],nuevosvalores[:,1],)\n",
    "plt.xlabel(\"PCA1\")\n",
    "plt.ylabel(\"PCA2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requiriendo una varianza específica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entremar el modelo: requerimos una varianza del 90%\n",
    "pca = PCA(0.9) \n",
    "\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevos componentes\n",
    "pd.DataFrame(np.round(pca.components_,2),columns=columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varianza\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los nuevos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevosvalores = pca.transform(X)\n",
    "pd.DataFrame(nuevosvalores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "- Para el dataset del Titanic busca los componentes que representen el 97% de la varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el dataset del Titanic\n",
    "df = pd.read_csv('../../../data/titanic/train.csv')\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar Columnas\n",
    "df_clean = df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores nulos\n",
    "df_clean['Age'].fillna(df_clean['Age'].mean(), inplace=True)  # Imputar edad con la media\n",
    "df_clean['Fare'].fillna(df_clean['Fare'].mean(), inplace=True)  # Imputar tarifa con la media\n",
    "df_clean.dropna(inplace=True)\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  categorizar\n",
    "df_clean['Sex'] = df_clean['Sex'].map({'male': 0, 'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar las variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.97)\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevos componentes\n",
    "pd.DataFrame(np.round(pca.components_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varianza\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevosvalores = pca.transform(X_scaled)\n",
    "pd.DataFrame(nuevosvalores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
