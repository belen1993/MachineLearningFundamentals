{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsqueda del mejor modelo (No supervisados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../../data/penguins/penguins.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Validación cruzada**\n",
    "\n",
    "En problemas no supervisados, no hay una variable objetivo para medir directamente el rendimiento del modelo. \n",
    "\n",
    "Sin embargo, la validación cruzada sigue siendo útil para:\n",
    "\n",
    "- Evaluar la estabilidad de los resultados (por ejemplo, si los clústeres son consistentes entre diferentes particiones de datos).\n",
    "- Identificar problemas de sobreajuste o subajuste.\n",
    "- Comparar el rendimiento de diferentes configuraciones de hiperparámetros.\n",
    "\n",
    "\n",
    "Ejemplo con K-Means con K-Folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = df[['Flipper Length (mm)', 'Culmen Length (mm)', 'Culmen Depth (mm)', 'Body Mass (g)']].dropna()\n",
    "\n",
    "# Configuración de K-Fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "silhouette_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    \n",
    "    # Entrenar K-Means en el conjunto de entrenamiento\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    kmeans.fit(X_train)\n",
    "    \n",
    "    # Predecir clústeres en el conjunto de prueba\n",
    "    labels = kmeans.predict(X_test)\n",
    "    \n",
    "    # Evaluar con Silhouette Score\n",
    "    score = silhouette_score(X_test, labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Resultado promedio\n",
    "print(f\"Silhouette Score promedio: {np.mean(silhouette_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptaciones Específicas por Tarea\n",
    "\n",
    "| Tarea | Métrica | Ejemplo |\n",
    "| --- | --- | --- |\n",
    "| Clustering | Silhouette Score, ARI, NMI | Validación cruzada K-Fold o Bootstrap para evaluar la estabilidad de los clústeres. |\n",
    "| Reducción de Dimensionalidad | Varianza Explicada | Dividir los datos y evaluar la varianza capturada en cada fold. |\n",
    "| Asociación | Support, Confidence, Lift | Dividir transacciones y evaluar la consistencia de las reglas generadas. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Curva de Aprendizaje**\n",
    "\n",
    "La curva de aprendizaje muestra cómo el rendimiento del modelo cambia en función del tamaño del conjunto de datos de entrenamiento. \n",
    "\n",
    "En problemas no supervisados, esta curva se puede construir utilizando métricas específicas del algoritmo.\n",
    "\n",
    "Ejemplo con K-Means:\n",
    "- Métrica : Silhouette Score o Inercia.\n",
    "- Procedimiento :\n",
    "    - Entrena el modelo con diferentes tamaños de subconjuntos del dataset.\n",
    "    - Evalúa la métrica seleccionada (por ejemplo, Silhouette Score) para cada tamaño.\n",
    "    - Grafica el tamaño del conjunto de datos en el eje x y la métrica en el eje y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Generar curva de aprendizaje para K-Means\n",
    "sizes = np.linspace(0.1, 1.0, 10)  # Fracciones del dataset\n",
    "scores = []\n",
    "\n",
    "for size in sizes:\n",
    "    sample_size = int(size * X.shape[0])\n",
    "    X_sample = X[:sample_size]\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_sample)\n",
    "    score = silhouette_score(X_sample, labels)\n",
    "    scores.append(score)\n",
    "\n",
    "# Graficar la curva de aprendizaje\n",
    "plt.plot(sizes * X.shape[0], scores, marker='o')\n",
    "plt.xlabel('Tamaño del conjunto de datos')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Curva de Aprendizaje para K-Means')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretación:\n",
    "- Si la métrica mejora significativamente al aumentar el tamaño del conjunto de datos, indica que el modelo necesita más datos para generalizar mejor.\n",
    "- Si la métrica se estabiliza rápidamente, sugiere que el modelo ya está aprovechando bien los datos disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Curva de Validación**\n",
    "\n",
    "La curva de validación evalúa el rendimiento del modelo en función de cambios en los hiperparámetros. En problemas no supervisados, esta curva se puede construir ajustando los hiperparámetros y evaluando métricas específicas.\n",
    "\n",
    "Ejemplo con DBSCAN:\n",
    "- Hiperparámetro : `eps` (radio de vecindad).\n",
    "- Métrica : Número de clústeres o Silhouette Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Probar diferentes valores de eps\n",
    "eps_values = np.linspace(0.1, 1.0, 10)\n",
    "scores = []\n",
    "n_clusters = []\n",
    "\n",
    "for eps in eps_values:\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=5)\n",
    "    labels = dbscan.fit_predict(X)\n",
    "    if len(set(labels)) > 1:  # Solo evaluar si hay más de un clúster\n",
    "        score = silhouette_score(X, labels)\n",
    "        scores.append(score)\n",
    "        n_clusters.append(len(set(labels)) - (1 if -1 in labels else 0))\n",
    "    else:\n",
    "        scores.append(-1)  # Asignar un valor bajo si no hay clústeres válidos\n",
    "        n_clusters.append(0)\n",
    "\n",
    "# Graficar la curva de validación\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('eps')\n",
    "ax1.set_ylabel('Silhouette Score', color=color)\n",
    "ax1.plot(eps_values, scores, marker='o', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Número de Clústeres', color=color)\n",
    "ax2.plot(eps_values, n_clusters, marker='x', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Curva de Validación para DBSCAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretación:\n",
    "- La curva muestra cómo cambia la métrica (Silhouette Score) y el número de clústeres al variar eps.\n",
    "- Un valor óptimo de eps equilibra un buen Silhouette Score con un número razonable de clústeres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptaciones Específicas por Tarea\n",
    "\n",
    "| Tarea | Métrica | Ejemplo |\n",
    "| --- | --- | --- |\n",
    "| Clustering | Silhouette Score, Inercia | Variación del Silhouette Score con el número de clústeres o tamaño del dataset. |\n",
    "| Reducción de Dimensionalidad | Varianza Explicada | Varianza explicada acumulada en función del número de componentes (PCA). |\n",
    "| Asociación | Support, Confidence, Lift | Cambio en las métricas al ajustar umbrales mínimos de soporte o confianza (Apriori). |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Afinar hiperparámetros**\n",
    "\n",
    "- La búsqueda de hiperparámetros para algoritmos no supervisados es un proceso clave para optimizar el rendimiento del modelo, ya que los hiperparámetros controlan aspectos fundamentales del comportamiento del algoritmo. \n",
    "- A diferencia de los modelos supervisados, donde se puede usar métricas como precisión o F1-score para evaluar el rendimiento, en los modelos no supervisados la evaluación depende de métricas específicas para cada tipo de tarea (clustering, reducción de dimensionalidad, etc.). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Métodos Generales para Búsqueda de Hiperparámetros\n",
    "Existen varias estrategias para buscar hiperparámetros óptimos:\n",
    "\n",
    "#### a) Grid Search\n",
    "- Define una cuadrícula de valores posibles para cada hiperparámetro.\n",
    "- Evalúa el modelo con todas las combinaciones posibles de hiperparámetros.\n",
    "- Selecciona la combinación que maximice/minimice una métrica de evaluación específica.\n",
    "\n",
    "Ejemplo con K-Means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Definir rango de valores para el hiperparámetro 'n_clusters'\n",
    "param_grid = {'n_clusters': range(2, 10)}\n",
    "\n",
    "best_score = -1\n",
    "best_params = None\n",
    "\n",
    "for n_clusters in param_grid['n_clusters']:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = {'n_clusters': n_clusters}\n",
    "\n",
    "print(f\"Mejores parámetros: {best_params}, Silhouette Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Random Search\n",
    "- En lugar de probar todas las combinaciones posibles, selecciona aleatoriamente un subconjunto de combinaciones de hiperparámetros.\n",
    "- Es más eficiente que Grid Search cuando el espacio de búsqueda es grande.\n",
    "\n",
    "Ejemplo con DBSCAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "# Definir rangos de valores para eps y min_samples\n",
    "eps_values = np.linspace(0.1, 1.0, 10)\n",
    "min_samples_values = range(2, 10)\n",
    "\n",
    "best_score = -1\n",
    "best_params = None\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(X_scaled)\n",
    "        if len(set(labels)) > 1:  # Solo evaluar si hay más de un clúster\n",
    "            score = silhouette_score(X_scaled, labels)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = {'eps': eps, 'min_samples': min_samples}\n",
    "\n",
    "print(f\"Mejores parámetros: {best_params}, Silhouette Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Métricas de Evaluación para Algoritmos No Supervisados\n",
    "La elección de la métrica depende del tipo de algoritmo y la tarea:\n",
    "\n",
    "a) Clustering\n",
    "- Silhouette Score : Mide qué tan bien están separados los clústeres entre sí y qué tan cohesionados están internamente.\n",
    "- Davies-Bouldin Index : Cuanto menor sea el valor, mejor será la calidad del clustering.\n",
    "- Calinski-Harabasz Index : Cuanto mayor sea el valor, mejor será la calidad del clustering.\n",
    "- Inercia (K-Means) : La suma de las distancias cuadradas dentro de los clústeres (se busca minimizar).\n",
    "\n",
    "b) Reducción de Dimensionalidad\n",
    "- Varianza Explicada (PCA) : Proporción de la varianza total capturada por los componentes principales.\n",
    "- Reconstrucción Error (NMF) : Diferencia entre los datos originales y los datos reconstruidos.\n",
    "- Visualización (t-SNE/UMAP) : Subjetiva, basada en la separación visual de grupos.\n",
    "\n",
    "c) Asociación\n",
    "- Support : Frecuencia relativa de un conjunto de elementos.\n",
    "- Confidence : Probabilidad condicional de que un conjunto de elementos ocurra junto a otro.\n",
    "- Lift : Mide cuánto más probable es que un conjunto de elementos ocurra juntos en comparación con el azar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "- Para el dataset del Titanic busca el mejor modelo para identificar los grupos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
