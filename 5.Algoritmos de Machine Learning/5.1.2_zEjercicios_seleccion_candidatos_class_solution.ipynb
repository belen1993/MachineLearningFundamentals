{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicios de selección de candidatos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clasificación \n",
    "Para el dataset del titanic (data/titanic)\n",
    "- Selecciona los 3 mejores modelos candidatos para este problema de clasificación basándote en su rendimiento (usando las métricas de precisión y F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato de los prints\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "def headr(text):\n",
    "    return ('\\n'+color.UNDERLINE + text + color.END+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "import pandas as pd\n",
    "\n",
    "titanic = pd.read_csv(\"../../data/titanic/train.csv\")\n",
    "target_column = \"Survived\"\n",
    "\n",
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Explorar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(titanic, title=\"Titanic Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Datos desbalanceados\n",
    "- Datos no normales\n",
    "- Datos no lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpiar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas irrelevantes\n",
    "\n",
    "discarded_columns = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    "titanic_cleaned = titanic.drop(discarded_columns, axis=1)\n",
    "titanic_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_cleaned.describe(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(titanic_cleaned)\n",
    "categorical_columns = categorical_columns_selector(titanic_cleaned)\n",
    "\n",
    "print(headr(\"Numerical columns\"), numerical_columns)\n",
    "print(headr(\"Categorical columns\"), categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores faltantes\n",
    "\n",
    "print(headr(\"Valores faltantes - original: \"), titanic_cleaned.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar valores faltantes\n",
    "titanic_cleaned[\"Age\"].fillna(titanic_cleaned[\"Age\"].median(), inplace=True)\n",
    "titanic_cleaned[\"Embarked\"].fillna(titanic_cleaned[\"Embarked\"].mode()[0], inplace=True)\n",
    "\n",
    "print(headr(\"Valores faltantes - imputados: \"), titanic_cleaned.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers\n",
    "\n",
    "# identificación\n",
    "IQR = titanic_cleaned[numerical_columns].quantile(0.75) - titanic_cleaned[numerical_columns].quantile(0.25)\n",
    "lower_bound = titanic_cleaned[numerical_columns].quantile(0.25) - (IQR * 3)\n",
    "upper_bound = titanic_cleaned[numerical_columns].quantile(0.75) + (IQR * 3)\n",
    "\n",
    "print(headr('lower_bound'),lower_bound)\n",
    "print(headr('upper_bound'),upper_bound)\n",
    "\n",
    "outliers = titanic_cleaned[numerical_columns][(titanic_cleaned[numerical_columns] < lower_bound) | (titanic_cleaned[numerical_columns] > upper_bound)]\n",
    "\n",
    "print(headr(\"Outliers:\"))\n",
    "outliers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazo\n",
    "\n",
    "# columnas con outliers\n",
    "columns_with_outliers = outliers.columns[outliers.count() > 0]\n",
    "columns_with_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para winsorizar una columna\n",
    "def winsorize_column(column, lower_bound, upper_bound):\n",
    "    return column.clip(lower=lower_bound, upper=upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procesamos todas las comumnas con outliers\n",
    "for col_name in columns_with_outliers:\n",
    "    titanic_cleaned[col_name] = winsorize_column(titanic_cleaned[col_name], lower_bound[col_name], upper_bound[col_name])\n",
    "\n",
    "outliers = titanic_cleaned[numerical_columns][(titanic_cleaned[numerical_columns] < lower_bound) | (titanic_cleaned[numerical_columns] > upper_bound)]\n",
    "\n",
    "print(headr(\"Outliers - winsorized:\"))\n",
    "outliers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocesar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características y target\n",
    "X = titanic_cleaned.drop(target_column, axis=1)\n",
    "y = titanic_cleaned[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidatos\n",
    "\n",
    "A partir del análisis previo:\n",
    "\n",
    "1. `LogisticRegression`\n",
    "2. `RandomForestClassifier` \n",
    "3. `GradientBoostingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(X)\n",
    "categorical_columns = categorical_columns_selector(X)\n",
    "\n",
    "print(headr(\"Numerical columns\"), numerical_columns)\n",
    "print(headr(\"Categorical columns\"), categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('numerical', StandardScaler(), numerical_columns),\n",
    "        ('categorical', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "pipelines = {\n",
    "    \"LogisticRegression\": Pipeline([('preprocessor', preprocessor),('classifier', LogisticRegression())]),\n",
    "    \"RandomForestClassifier\": Pipeline([('preprocessor', preprocessor),('classifier', RandomForestClassifier())]),\n",
    "    \"GradientBoostingClassifier\": Pipeline([('preprocessor', preprocessor),('classifier', GradientBoostingClassifier())]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_train(name, pipeline, cv):\n",
    "    print(headr(f\"Entrenar {name}\"))\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=cv, scoring=\"accuracy\", return_estimator=True, return_train_score=True)\n",
    "    trained_model = cv_results[\"estimator\"][0]\n",
    "    scores = pd.DataFrame(cv_results)\n",
    "\n",
    "    print(\"test score (mean-std): {0:.2f} - {1:.2f}\".format(scores[\"test_score\"].mean(), scores[\"test_score\"].std()))\n",
    "    print(\"train score (mean-std): {0:.2f} - {1:.2f}\".format(scores[\"train_score\"].mean(), scores[\"train_score\"].std()))\n",
    "    print(\"params:\", pipeline.named_steps.get(\"classifier\").get_params())\n",
    "\n",
    "    y_pred = trained_model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    return {\"acc\": round(scores[\"test_score\"].mean(), 2), \"f1\": round(f1, 2),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvss = ShuffleSplit(n_splits=40, test_size=0.2, random_state=0)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    results[name] = cv_train(name, pipeline, cvss)\n",
    "\n",
    "print(headr(\"Resultados:\"))\n",
    "results_df=pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva de aprenizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de aprendizaje\n",
    "\n",
    "train_sizes = np.linspace(0.1, 1.0, num=5, endpoint=True)\n",
    "\n",
    "def generate_learning_curves(name, pipeline, X, y, train_sizes):\n",
    "    results = learning_curve(pipeline, X, y, train_sizes=train_sizes,\n",
    "                             cv=cvss, scoring='accuracy')\n",
    "    \n",
    "    train_size, train_scores, test_scores = results[:3]\n",
    "\n",
    "    # graficar la curva.\n",
    "    plt.errorbar(train_size, train_scores.mean(axis=1),\n",
    "                 yerr=train_scores.std(axis=1), label=\"Error de entrenamiento\")\n",
    "    plt.errorbar(train_size, test_scores.mean(axis=1),\n",
    "                 yerr=test_scores.std(axis=1), label=\"Error de prueba\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Número de muestras en el conjunto de entrenamiento\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.title(\"Curva de aprendizaje para {name}\".format(name=name))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipeline_name, pipeline_obj in pipelines.items():\n",
    "    generate_learning_curves(pipeline_name, pipeline_obj, X, y, train_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de validación\n",
    "\n",
    "def generate_validation_curves(name, pipeline, X, y, param_name, param_range):\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        pipeline, X, y, param_name=param_name, param_range=param_range,\n",
    "        cv=cvss, scoring=\"accuracy\")\n",
    "\n",
    "    # graficar la curva.\n",
    "    plt.plot(param_range, train_scores.mean(\n",
    "        axis=1), label=\"Error de entrenamiento\")\n",
    "    plt.plot(param_range, test_scores.mean(axis=1), label=\"Error de prueba\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel(\"Valor del ({param_name})\".format(\n",
    "        param_name=param_name))\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Curva de validación para {name}\".format(name=name))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pname = 'LogisticRegression'\n",
    "Cs = [0,0.1, 1, 5, 10, 12]\n",
    "generate_validation_curves(pname, pipelines[pname], X, y, 'classifier__C', Cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pname = 'RandomForestClassifier'\n",
    "n_estimators_ops = [1,2,3,4,5]\n",
    "generate_validation_curves(pname, pipelines[pname], X, y, 'classifier__n_estimators', n_estimators_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pname = 'GradientBoostingClassifier'\n",
    "n_estimators_ops = [1,2,3,4,5,10]\n",
    "generate_validation_curves(pname, pipelines[pname], X, y, 'classifier__n_estimators', n_estimators_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afinar hiperparámentros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pname = 'GradientBoostingClassifier'\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [1, 2, 3, 4, 5, 10],\n",
    "    'classifier__max_depth': [1, 2, 3, 4, 5],\n",
    "    'classifier__learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipelines[pname], param_grid, cv=cvss, scoring=\"accuracy\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(headr(pname))\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(f\"Mejor accuracy: {grid_search.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Afinar hiperparámetros otros modelos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-entrenar + re-evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('numerical', StandardScaler(), numerical_columns),\n",
    "        ('categorical', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "pipelines = {\n",
    "    \"LogisticRegression\": Pipeline([('preprocessor', preprocessor),('classifier', LogisticRegression())]),\n",
    "    \"RandomForestClassifier\": Pipeline([('preprocessor', preprocessor),('classifier', RandomForestClassifier())]),\n",
    "    \"GradientBoostingClassifier\": Pipeline([('preprocessor', preprocessor),('classifier', GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=10))]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final = {}\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    results_final[name] = cv_train(name, pipeline, cvss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(headr(\"Resultados:\"))\n",
    "results_df = pd.DataFrame(results_final)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resultado\n",
    "\n",
    "GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mejorar el resultado\n",
    "\n",
    "Añadiendo más características: por ejemplo, procesando \"Cabin\" para generar una categoría"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
