{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinar múltiples datasets para ML \n",
    "\n",
    "Para muchos casos de uso, la combinación de información de diferentes datasets puede ser interesante para mejorar el rendimiento de un modelo, especialmente cuando el número de muestras de al menos uno de los conjuntos de datos es pequeño.\n",
    "\n",
    "Un desafío adicional en tales casos es que las características de estos conjuntos de datos no son idénticas, a pesar de que hay algunas características comúnmente compartidas entre los conjuntos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4624723",
   "metadata": {},
   "source": [
    "## **Proceso de combinación**\n",
    "\n",
    "### **1. Limpieza de datos**\n",
    "Antes de pensar en combinar datasets, es **crucial limpiarlos** individualmente. \n",
    "- La limpieza de datos implica eliminar o corregir imprecisiones, manejar valores faltantes y estandarizar los formatos de datos. \n",
    "- Por ejemplo, se puede usar `fillna()` de Pandas para abordar los valores nulos. \n",
    "- Asegurar que cada conjunto de datos esté limpio y consistente es la base para una integración exitosa. \n",
    "- Es como preparar ingredientes antes de combinarlos en una comida: cada uno debe estar fresco y listo para contribuir al sabor general.\n",
    "\n",
    "\n",
    "### **2. Matching de esquemas**\n",
    "Cuando los datasets provienen de diferentes fuentes, a menudo tienen esquemas o estructuras dispares. \n",
    "- El matching de esquemas es el proceso de encontrar correspondencias entre elementos de datos que representan el mismo concepto en todos los datasets. \n",
    "- Es posible que se deba cambiar el nombre de columnas o reformatear los tipos de datos para alinearlas. \n",
    "- Por ejemplo, si un conjunto de datos tiene una columna llamada \"Fecha de nacimiento\" y otra tiene \"DOB\" (Date of Birth), se cambiará el nombre de estas columnas para que coincidan antes de fusionar.\n",
    "\n",
    "\n",
    "### **3. Feature Engineering**\n",
    "La ingeniería de características es el arte de transformar datos sin procesar en características que representan mejor el problema subyacente a los modelos predictivos. \n",
    "- Al combinar datasets, es posible que se deban crear nuevas características o modificar las existentes para que sean compatibles en los datasets. \n",
    "- Por ejemplo, si un conjunto de datos tiene la temperatura en Celsius y otro en Fahrenheit, se podría crear una nueva característica en una escala unificada o convertir las mediciones para que coincida la una con la otra.\n",
    "\n",
    "\n",
    "### **4. Fusión de datos**\n",
    "La fusión de datos es el proceso real de integrar múltiples datasets en un conjunto de datos único, consistente y comprehensivo. \n",
    "- Aquí se utilizan técnicas como la concatenación, donde se apilan los datasets verticalmente u horizontalmente, o métodos más complejos como joins. \n",
    "- Por ejemplo, puede usar `pd.concat()` para un apilamiento sencillo, o `p.merge()` para mezclar datasets basados ​​en claves comunes.\n",
    "\n",
    "### **5. Gestión de duplicados**\n",
    "Después de fusionar datasets, se pueden encontrar entradas duplicadas. \n",
    "- Los duplicados pueden sesgar el análisis y conducir a conclusiones erroneas. \n",
    "- Es esencial identificar y eliminar estos duplicados para mantener la integridad de sus datos. \n",
    "- Esto se puede hacer utilizando funciones como `drop_dupplicates()`, que permite especificar el subconjunto de columnas a considerar para identificar duplicados.\n",
    "\n",
    "### **6. Verificación de consistencia**\n",
    "Una vez que se combinan los datasets, se deben realizar verificaciones de consistencia para garantizar que los datos tengan sentido. \n",
    "- Buscar anomalías que puedan indicar problemas con la fusión, como tipos de datos no coincidentes o valores ilógicos que no se alineen con el resto de su conjunto de datos. \n",
    "- Este paso es similar a la revisión de un documento después de fusionar contenidos de diferentes fuentes. Se trata de identificar y corregir errores para garantizar una narración perfecta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f32cdd",
   "metadata": {},
   "source": [
    "## **Fusión de datos**\n",
    "Combinar dos datasets con características distintas, pero con 2 características en común, requiere elegir una estrategia que preserve la información relevante y evite problemas como la pérdida de datos o la creación de redundancias innecesarias. Aquí tienes algunas estrategias a considerar para preparar los datos antes de entrenar un modelo en **Scikit-Learn**:\n",
    "\n",
    "\n",
    "### **1. Unión basada en las características comunes (Join/Merge)**\n",
    "#### **1.1. Unión por clave común (Join)**\n",
    "Si las dos características comunes pueden actuar como **claves únicas**, podemos unir los datasets de varias maneras:\n",
    "- **Inner Join**: Mantiene solo las filas que tienen coincidencia en ambas tablas.  \n",
    "- **Outer Join**: Mantiene todas las filas de ambos datasets y completa con valores `NaN` cuando falta información.  \n",
    "- **Left/Right Join**: Mantiene todas las filas de un dataset y solo las coincidentes del otro.  \n",
    "\n",
    "**Ejemplo**:\n",
    "```python\n",
    "df_merged = df1.merge(df2, on=['feature1', 'feature2'], how='inner')  # 'outer', 'left', 'right'\n",
    "```\n",
    "\n",
    "**Cuándo usarlo**:  \n",
    "- Si los datasets tienen información complementaria sobre las mismas observaciones.  \n",
    "- Si las características comunes identifican la misma entidad en ambos datasets.  \n",
    "\n",
    "\n",
    "### **2. Concatenación de datasets (Stacking)**\n",
    "Si los datasets representan observaciones similares pero con distintas características, se pueden **concatenar verticalmente** (aumentando el número de filas) o **horizontalmente** (aumentando el número de columnas).\n",
    "\n",
    "#### **2.1. Concatenación horizontal (Column-wise)**\n",
    "Si los datos comparten el mismo orden y cada fila representa la misma entidad en ambos datasets:\n",
    "```python\n",
    "df_combined = pd.concat([df1, df2.drop(columns=['feature1', 'feature2'])], axis=1)\n",
    "```\n",
    "\n",
    "**Cuándo usarlo**:  \n",
    "- Si cada fila en ambos datasets representa la misma entidad y están alineadas en el mismo orden.  \n",
    "\n",
    "#### **2.2. Concatenación vertical (Row-wise)**\n",
    "Si los datasets contienen **observaciones similares pero con diferentes muestras**:\n",
    "```python\n",
    "df_combined = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "```\n",
    "**Cuándo usarlo**:  \n",
    "- Si los datasets contienen las mismas variables pero diferentes ejemplos.  \n",
    "\n",
    "\n",
    "### **3. Creación de nuevas características a partir de los datasets**\n",
    "Si ambos datasets contienen información complementaria, podemos usar técnicas como:\n",
    "- **Feature Engineering**: Crear nuevas características a partir de la información de ambos datasets.  \n",
    "- **Agregaciones y Estadísticas**: Si un dataset contiene datos agrupados (ej. transacciones de usuarios), podemos agregar la información y unirla al otro dataset.  \n",
    "```python\n",
    "df_grouped = df2.groupby(['feature1', 'feature2']).agg({'some_feature': 'mean'}).reset_index()\n",
    "df_combined = df1.merge(df_grouped, on=['feature1', 'feature2'], how='left')\n",
    "```\n",
    "\n",
    "**Cuándo usarlo**:  \n",
    "- Si un dataset tiene información granular y el otro información agregada.  \n",
    "\n",
    "\n",
    "### **4. Imputación y tratamiento de valores faltantes**\n",
    "Después de combinar datasets, es posible que haya valores faltantes (`NaN`). Algunas estrategias para tratarlos incluyen:\n",
    "- **Eliminar filas con valores faltantes**: `df.dropna()`\n",
    "- **Rellenar con la media/mediana/moda**: `df.fillna(df.mean())`\n",
    "- **Usar un imputador de `scikit-learn`**:\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')  # O 'median', 'most_frequent'\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "```\n",
    "\n",
    "**Cuándo usarlo**:  \n",
    "- Si el join o la concatenación dejan valores nulos y no queremos perder información.  \n",
    "\n",
    "\n",
    "### **5. Reducción de Dimensionalidad**\n",
    "Si al combinar los datasets obtenemos muchas características irrelevantes, podemos reducirlas mediante:\n",
    "- **PCA (Análisis de Componentes Principales)**  \n",
    "- **Selección de características basada en correlación o importancia**  \n",
    "\n",
    "**Ejemplo usando `PCA`:**\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)  # Reducir a 10 dimensiones\n",
    "X_reduced = pca.fit_transform(df_combined)\n",
    "```\n",
    "\n",
    "**Cuándo usarlo**:  \n",
    "- Si la combinación genera muchas características redundantes o altamente correlacionadas.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483528f",
   "metadata": {},
   "source": [
    "### **Conclusiones**\n",
    "- **Si los datasets representan las mismas entidades y tienen información complementaria** → Usa **Merge/Join**  \n",
    "- **Si los datasets tienen estructuras similares pero distintas muestras** → Usa **Concatenación vertical**  \n",
    "- **Si un dataset tiene datos agregados** → Usa **Agregación y Feature Engineering**  \n",
    "- **Si la combinación genera muchas características irrelevantes** → Usa **Reducción de dimensionalidad**  \n",
    "\n",
    "> **Tip:** Probar distintas estrategias y evaluar el rendimiento con validación cruzada puede ayudar a encontrar la mejor forma de combinar los datasets. 🚀"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
