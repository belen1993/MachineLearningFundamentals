{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Scikit-learn\n",
    "\n",
    "Scikit-learn es una de las librerías más populares de Python para machine learning. \n",
    "\n",
    "https://scikit-learn.org\n",
    "\n",
    "Proporciona herramientas simples y eficientes para tareas como clasificación, regresión, clustering y reducción de dimensionalidad. \n",
    "\n",
    "En este notebook, exploraremos los conceptos básicos de Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Introducción a Scikit-learn y su API**\n",
    "\n",
    "Scikit-learn sigue una API consistente y bien documentada. \n",
    "\n",
    "- https://scikit-learn.org/stable/api/index.html\n",
    "\n",
    "\n",
    "Los principales componentes son:\n",
    "\n",
    "- **Estimadores**: Objetos que implementan algoritmos de machine learning (por ejemplo, `LinearRegression`, `RandomForestClassifier`).\n",
    "    - Ver *4.2.ResumenAPI_scikitlearn*\n",
    "- **Transformadores**: Objetos que preprocesan los datos (por ejemplo, `StandardScaler`, `PCA`).\n",
    "- **Predictores**: Estimadores que pueden hacer predicciones (por ejemplo, `predict()`).\n",
    "\n",
    "### **Ejemplo: Cargar un Dataset y Aplicar un Modelo Simple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar Scikit-learn y cargar un dataset de ejemplo\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el dataset Iris\n",
    "iris = load_iris()\n",
    "X = iris.data  # Características\n",
    "y = iris.target  # Target\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "print(\"Características (X):\")\n",
    "print(X[:5])\n",
    "print(\"\\nEtiquetas (y):\")\n",
    "print(y[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. División de Datos en Entrenamiento y Prueba**\n",
    "\n",
    "Es fundamental dividir los datos en conjuntos de entrenamiento y prueba para evaluar el rendimiento del modelo.\n",
    "\n",
    "- Antes de abarcar cualquier transformación en nuestro dataset, debemos primero dividir nuestros datos entre train y test. \n",
    "\n",
    "    - La idea es que los datos de test no se tengan considerados en niguna transformación, como si fuesen nuevos de verdad.\n",
    "\n",
    "- Así pues, para realizar el split entre train y test contamos con la función `train_test_split`, la cual devuelve una tupla con cuatro elementos: `Xtrain`, `Xtest`, `Ytrain` e `Ytest`.\n",
    "\n",
    "Asimismo, para que el split sea reproducible podemos fijar la semilla usando el parámetro `random_state`.\n",
    "\n",
    "### **Ejemplo: Dividir el Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Preprocesamiento de Datos**\n",
    "\n",
    "Antes de entrenar un modelo, es común preprocesar las características.\n",
    "\n",
    "- Imputación de Valores Perdidos con Sklearn\n",
    "    - Imputación de valores perdidos univariantes\n",
    "    - Imputación multivariante de valores perdidos\n",
    "    - Imputación mediante kNN\n",
    "- Transformación de los datos\n",
    "    - Modificar la distribución de una variable\n",
    "    - Normalizar o estandarizar los datos\n",
    "    - One-hot encoding\n",
    "\n",
    "\n",
    "### **Ejemplo: Escalar las Características**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar las características para que tengan media 0 y desviación estándar 1\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nCaracterísticas escaladas (primeras filas):\")\n",
    "print(X_train_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Entrenamiento de un Modelo**\n",
    "\n",
    "Dentro de Sklearn contamos con muchísimas familias de modelos de Machine Learning diferentes que podemos aplicar y, dentro de cada familia, puede haber varios modelos diferentes.\n",
    "\n",
    "Poe lo tanto, en la siguiente tabla te incluyo todas las familias de modelos de Machine Learning junto con el nombre del módulo donde se encuentran:\n",
    "\n",
    "|Modelo Supervisado|Module|\n",
    "|------------------|------|\n",
    "|Linear Models|linear_model|\n",
    "|Linear and Quadratic Discriminant Analysis|discriminant_analysis|\n",
    "|Kernel ridge regression|kernel_ridge|\n",
    "|Support Vector Machines|svm|\n",
    "|Stochastic Gradient Descent|linear_model|\n",
    "|Nearest Neighbors|neighbors|\n",
    "|Gaussian Processes|gaussian_process|\n",
    "|Cross decomposition|cross_decomposition|\n",
    "|Naive Bayes|naive_bayes|\n",
    "|Decision Trees|tree|\n",
    "|Ensemble methods|ensemble|\n",
    "|Multiclass and multioutput algorithms|multiclass & multioutput|\n",
    "|Semi-supervised learning|semi_supervised|\n",
    "|Isotonic regression|isotonic|\n",
    "|Probability calibration|calibration|\n",
    "|Neural network models (supervised)|neural_networ|\n",
    "\n",
    "\n",
    "En el caso de los modelos no supervisados pasa un poco parecido ya que cuenta con muchos modelos no supervisados que podemos encontrarn en diferentes módulos:\n",
    "\n",
    "|Model|Module|\n",
    "|---|---|\n",
    "|Gaussian mixture models|GaussianMixture|\n",
    "|Manifold learning|manifold|\n",
    "|Clustering|cluster|\n",
    "|Decomposing signals in components (matrix factorization problems)|decomposition|\n",
    "|Covariance estimation|covariance|\n",
    "|Neural network models (unsupervised)|neural_network|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar un modelo de clasificación usando el algoritmo **K-Nearest Neighbors (KNN)**.\n",
    "\n",
    "### **Ejemplo: Entrenar un Modelo KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nPredicciones (y_pred):\")\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Evaluación del Modelo y Métricas**\n",
    "\n",
    "La forma de evaluar el rendimiento de un modelo es analizar cómo de buenas son sus predicciones. \n",
    "\n",
    "Para ello Sklearn cuenta con diferentes funciones dentro del módulo metrics de Sklearn.\n",
    "\n",
    "Es crucial evaluar el rendimiento del modelo utilizando métricas adecuadas.\n",
    "\n",
    "### **Ejemplo: Calcular la Precisión (Accuracy)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nPrecisión del modelo: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Otras Métricas Comunes**\n",
    "\n",
    "Scikit-learn proporciona varias métricas para evaluar modelos. Algunas de las más comunes son:\n",
    "\n",
    "- **Matriz de Confusión**: Para problemas de clasificación.\n",
    "- **Precisión, Recall y F1-Score**: Para evaluar el rendimiento en clases desbalanceadas.\n",
    "- **Error Cuadrático Medio (MSE)**: Para problemas de regresión.\n",
    "\n",
    "\n",
    "#### **Ejemplo: Matriz de Confusión y Reporte de Clasificación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Reporte de clasificación\n",
    "class_report = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Ejercicio**\n",
    "\n",
    "Entrenar un modelo de regresión lineal usando el dataset **Boston Housing** (load_boston) y evalúa su rendimiento utilizando el **Error Cuadrático Medio (MSE)**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
