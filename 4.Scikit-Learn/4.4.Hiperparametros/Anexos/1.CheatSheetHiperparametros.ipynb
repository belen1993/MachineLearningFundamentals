{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros de algoritmos ML en Scikit-Learn\n",
    "\n",
    "### **Regresión**\n",
    "| Algoritmo               | Clase de Scikit-Learn            | Hiperparámetros Principales | Enlace Oficial |\n",
    "|-------------------------|---------------------------------|-----------------------------|----------------|\n",
    "| Regresión Lineal        | `LinearRegression`             | `fit_intercept`, `normalize` | [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) |\n",
    "| Regresión Ridge        | `Ridge`                         | `alpha`, `solver` | [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) |\n",
    "| Regresión Lasso        | `Lasso`                         | `alpha`, `max_iter` | [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) |\n",
    "| Regresión ElasticNet   | `ElasticNet`                    | `alpha`, `l1_ratio`, `max_iter` | [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) |\n",
    "| Support Vector Regression (SVR) | `SVR`                 | `kernel`, `C`, `epsilon` | [SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) |\n",
    "| Random Forest Regressor | `RandomForestRegressor`        | `n_estimators`, `max_depth`, `min_samples_split` | [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) |\n",
    "| Gradient Boosting Regressor | `GradientBoostingRegressor` | `n_estimators`, `learning_rate`, `max_depth` | [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) |\n",
    "\n",
    "### **Clasificación**\n",
    "| Algoritmo              | Clase de Scikit-Learn           | Hiperparámetros Principales | Enlace Oficial |\n",
    "|------------------------|--------------------------------|-----------------------------|----------------|\n",
    "| Regresión Logística    | `LogisticRegression`          | `C`, `penalty`, `solver` | [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) |\n",
    "| K-Nearest Neighbors    | `KNeighborsClassifier`        | `n_neighbors`, `metric`, `weights` | [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) |\n",
    "| Support Vector Machine | `SVC`                         | `kernel`, `C`, `gamma` | [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) |\n",
    "| Árbol de Decisión      | `DecisionTreeClassifier`      | `criterion`, `max_depth`, `min_samples_split` | [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) |\n",
    "| Random Forest         | `RandomForestClassifier`       | `n_estimators`, `max_depth`, `min_samples_split` | [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) |\n",
    "| Gradient Boosting     | `GradientBoostingClassifier`   | `n_estimators`, `learning_rate`, `max_depth` | [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) |\n",
    "| Naive Bayes           | `GaussianNB`, `MultinomialNB`  | `var_smoothing` (Gaussian), `alpha` (Multinomial) | [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) |\n",
    "\n",
    "### **Agrupamiento (Clustering)**\n",
    "| Algoritmo              | Clase de Scikit-Learn          | Hiperparámetros Principales | Enlace Oficial |\n",
    "|------------------------|------------------------------|-----------------------------|----------------|\n",
    "| K-Means               | `KMeans`                     | `n_clusters`, `init`, `max_iter` | [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) |\n",
    "| DBSCAN                | `DBSCAN`                     | `eps`, `min_samples`, `metric` | [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) |\n",
    "| Mean Shift            | `MeanShift`                  | `bandwidth`, `bin_seeding` | [MeanShift](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html) |\n",
    "\n",
    "### **Reducción de Dimensionalidad**\n",
    "| Algoritmo              | Clase de Scikit-Learn         | Hiperparámetros Principales | Enlace Oficial |\n",
    "|------------------------|-----------------------------|-----------------------------|----------------|\n",
    "| PCA (Análisis de Componentes Principales) | `PCA`  | `n_components`, `svd_solver` | [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) |\n",
    "| t-SNE                 | `TSNE`                      | `n_components`, `perplexity`, `learning_rate` | [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condiciones de Uso de Algoritmos de Machine Learning en Scikit-Learn\n",
    "\n",
    "### **Regresión**\n",
    "| Algoritmo | Cuándo Usarlo | Condiciones de Uso |\n",
    "|-----------|-------------|--------------------|\n",
    "| **Regresión Lineal** (`LinearRegression`) | Cuando la relación entre variables es lineal. | Supone independencia de las variables predictoras, sin multicolinealidad significativa. |\n",
    "| **Regresión Ridge** (`Ridge`) | Cuando hay multicolinealidad en los datos. | Agrega regularización L2 para evitar sobreajuste. |\n",
    "| **Regresión Lasso** (`Lasso`) | Cuando se busca selección de características. | Usa regularización L1 para reducir coeficientes a cero, eliminando características irrelevantes. |\n",
    "| **ElasticNet** (`ElasticNet`) | Cuando se necesita un balance entre Ridge y Lasso. | Mezcla L1 y L2, útil cuando hay muchas variables correlacionadas. |\n",
    "| **Support Vector Regression (SVR)** (`SVR`) | Para problemas de regresión con datos no lineales. | Sensible a la escala de los datos, requiere normalización. |\n",
    "| **Random Forest Regressor** (`RandomForestRegressor`) | Cuando se necesita manejar relaciones no lineales y reducir el sobreajuste. | Adecuado para conjuntos de datos grandes y variables con relaciones complejas. |\n",
    "| **Gradient Boosting Regressor** (`GradientBoostingRegressor`) | Para obtener predicciones de alta precisión en problemas de regresión. | Puede ser propenso al sobreajuste si no se ajusta correctamente. |\n",
    "\n",
    "### **Clasificación**\n",
    "| Algoritmo | Cuándo Usarlo | Condiciones de Uso |\n",
    "|-----------|-------------|--------------------|\n",
    "| **Regresión Logística** (`LogisticRegression`) | Para clasificación binaria o multiclase cuando los datos son linealmente separables. | Supone independencia de predictores, sensible a valores atípicos. |\n",
    "| **K-Nearest Neighbors (KNN)** (`KNeighborsClassifier`) | Cuando se necesita un modelo simple y sin supuestos fuertes. | No es eficiente en grandes volúmenes de datos, sensible a la escala de las variables. |\n",
    "| **Support Vector Machine (SVM)** (`SVC`) | Para clasificación en espacios con dimensiones altas. | Sensible a la escala de los datos, puede ser costoso en grandes volúmenes. |\n",
    "| **Árbol de Decisión** (`DecisionTreeClassifier`) | Cuando se necesita un modelo interpretable y fácil de visualizar. | Propenso al sobreajuste si no se poda correctamente. |\n",
    "| **Random Forest** (`RandomForestClassifier`) | Para problemas con muchas variables y cuando se necesita robustez. | Reduce el sobreajuste de los árboles de decisión individuales. |\n",
    "| **Gradient Boosting** (`GradientBoostingClassifier`) | Para mejorar el rendimiento en problemas complejos de clasificación. | Sensible a hiperparámetros, puede ser más lento que Random Forest. |\n",
    "| **Naive Bayes** (`GaussianNB`, `MultinomialNB`) | Para clasificación de texto y datos categóricos. | Supone independencia entre las características, no siempre realista. |\n",
    "\n",
    "### **Agrupamiento (Clustering)**\n",
    "| Algoritmo | Cuándo Usarlo | Condiciones de Uso |\n",
    "|-----------|-------------|--------------------|\n",
    "| **K-Means** (`KMeans`) | Cuando se conoce el número de grupos en los datos. | Sensible a valores atípicos, requiere elección de `k`. |\n",
    "| **DBSCAN** (`DBSCAN`) | Para datos con densidad variable y detección de outliers. | No requiere definir el número de clusters, pero depende de `eps` y `min_samples`. |\n",
    "| **Mean Shift** (`MeanShift`) | Cuando no se conoce el número de clusters de antemano. | Automáticamente detecta el número de clusters, pero es computacionalmente costoso. |\n",
    "\n",
    "### **Reducción de Dimensionalidad**\n",
    "| Algoritmo | Cuándo Usarlo | Condiciones de Uso |\n",
    "|-----------|-------------|--------------------|\n",
    "| **PCA** (`PCA`) | Para reducir la dimensionalidad preservando la varianza de los datos. | Supone que los componentes principales explican la variabilidad más relevante. |\n",
    "| **t-SNE** (`TSNE`) | Para visualizar datos en espacios de alta dimensión. | Requiere ajuste fino de hiperparámetros (`perplexity` y `learning_rate`). |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
