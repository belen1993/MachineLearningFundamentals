{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62488b43",
   "metadata": {},
   "source": [
    "# Overfit - Generalización - Underfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da06a76",
   "metadata": {},
   "source": [
    "Vamos a poner los dos errores en perspectiva y mostraremos cómo pueden ayudarnos a saber si nuestro modelo generaliza, sobreajusta o subajusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "data, target = housing.data, housing.target\n",
    "target *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20bf8fe",
   "metadata": {},
   "source": [
    "# Overfitting vs. underfitting\n",
    "Para comprender mejor el rendimiento de generalización de nuestro modelo y tal vez encontrar información sobre cómo mejorarlo, compararemos el error de prueba con el error de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0788d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por lo tanto, necesitamos calcular el error en el conjunto de entrenamiento, con la función cross_validate.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=30, test_size=0.2)\n",
    "cv_results = cross_validate(regressor, data, target,\n",
    "                            cv=cv, scoring=\"neg_mean_absolute_error\",\n",
    "                            return_train_score=True, n_jobs=2)\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358796da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La validación cruzada utiliza el error absoluto medio negativo.\n",
    "# Transformamos el error en  positivo.\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "scores[[\"train error\", \"test error\"]] = -cv_results[\n",
    "    [\"train_score\", \"test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48997014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores.plot.hist(bins=50, edgecolor=\"black\")\n",
    "plt.xlabel(\"Error absoluto medio (k$)\")\n",
    "_ = plt.title(\"Distribución de errores de entrenamiento y pruebas en la validación cruzada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d2cb8",
   "metadata": {},
   "source": [
    "Al graficar la distribución de los errores de entrenamiento y prueba, obtenemos información sobre si nuestro modelo está sobreajustando, subajustando (o ambos al mismo tiempo).\n",
    "\n",
    "Aquí, observamos un **error de entrenamiento pequeño (cero)**, lo que significa que el modelo **no está subajustando**: \n",
    "- es lo suficientemente flexible como para capturar cualquier variación presente en el conjunto de entrenamiento.\n",
    "\n",
    "Sin embargo, el **error de prueba significativamente grande** nos dice que el modelo está **sobre-ajustando**:\n",
    "- el modelo ha memorizado muchas variaciones del set de entrenamiento que podrían considerarse \"ruidosos\" porque no generalizan para ayudarnos a hacer una buena predicción en el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f187e0e",
   "metadata": {},
   "source": [
    "# Curva de validación\n",
    "\n",
    "Algunos hiperparámetros de modelo suelen ser la clave para pasar de un modelo que subajusta a un modelo que se sobreajusta, con suerte atravesar una región en la que podemos obtener un buen equilibrio entre los dos. \n",
    "\n",
    "Podemos verlo trazando una **curva de validación**.\n",
    "\n",
    "- Esta curva también se puede aplicar al experimento anterior y varía el valor de un hiperparámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab0185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Para el árbol de decisión, el parámetro max_depth se utiliza para controlar la compensación entre subajuste y el sobreajuste.\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "max_depth = [1, 5, 10, 15, 20, 25]\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    regressor, data, target, param_name=\"max_depth\", param_range=max_depth,\n",
    "    cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=2)\n",
    "train_errors, test_errors = -train_scores, -test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trazamos los errores de entrenamiento y prueba (así como sus desviaciones).\n",
    "\n",
    "plt.plot(max_depth, train_errors.mean(axis=1), label=\"Error de entrenamiento\")\n",
    "plt.plot(max_depth, test_errors.mean(axis=1), label=\"Error de prueba\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Profundidad máxima del árbol de decisión (max_depth)\")\n",
    "plt.ylabel(\"Error absoluto medio (k$)\")\n",
    "plt.title(\"Curva de validación para el árbol de decisión\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99303b0e",
   "metadata": {},
   "source": [
    "La curva de validación se puede dividir en tres áreas:\n",
    "\n",
    "- Para **max_depth < 10**, el árbol de decisión subajusta. \n",
    "    - El error de entrenamiento y, por lo tanto, el error de prueba es alto.\n",
    "    - El modelo está demasiado limitado y no puede capturar gran parte de la variabilidad de la variable objetivo.\n",
    "- La región **alrededor de max_depth = 10** corresponde al parámetro para el cual el árbol de decisión **mejor ajusta**.\n",
    "    - Es lo suficientemente flexible como para capturar una fracción de la variabilidad del objetivo que se generaliza, sin memorizar todo el ruido en el objetivo.\n",
    "- Para **max_depth > 10**, el árbol de decisión sobreajusta.\n",
    "    - El error de entrenamiento se vuelve muy pequeño, mientras que el error de prueba aumenta.En esta región, los modelos crean decisiones específicamente para muestras ruidosas que dañan su capacidad para generalizar para probar los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e9ef38",
   "metadata": {},
   "source": [
    "Tener en cuenta que para **max_depth = 10**, el modelo sobreajusta un poco, ya que hay una brecha entre el error de entrenamiento y el error de prueba.\n",
    "\n",
    "También puede potencialmente subajustar un poco al mismo tiempo, porque el error de entrenamiento aún está lejos de ser cero (más de 30 k$)\n",
    "- lo que significa que el modelo aún podría estar demasiado limitado para modelar partes interesantes de los datos.\n",
    "\n",
    "<br>\n",
    "    \n",
    "    \n",
    "Sin embargo, **el error de prueba  es mínimo, y esto es lo que realmente importa**.\n",
    "- Este es el mejor compromiso que podríamos alcanzar simplemente ajustando este parámetro.\n",
    "\n",
    "<br>\n",
    "\n",
    "> Asimismo, tener en cuenta que mirar los errores medios es bastante limitante. Debemos analizar la **desviación estándar** para evaluar la dispersión de la puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d4623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos repetir la misma gráfica, pero esta vez, añadiendo información para mostrar la desviación estándar de los errores.\n",
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.errorbar.html\n",
    "\n",
    "plt.errorbar(max_depth, train_errors.mean(axis=1),\n",
    "             yerr=train_errors.std(axis=1), label='Error de entrenamiento')\n",
    "plt.errorbar(max_depth, test_errors.mean(axis=1),\n",
    "             yerr=test_errors.std(axis=1), label='Error de prueba')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Profundidad máxima del árbol de decisión (max_depth)\")\n",
    "plt.ylabel(\"Error absoluto medio (k$)\")\n",
    "plt.title(\"Curva de validación para el árbol de decisión\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5acb2f",
   "metadata": {},
   "source": [
    "> **Saber más**: https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8cc4ce",
   "metadata": {},
   "source": [
    "## **Ejercicio**\n",
    "\n",
    "Para el dataset \"house-prices/full.csv\" y usando Ridge: \n",
    "\n",
    "- Haz una evaluación de overfitting-underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef280eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "haouses = pd.read_csv(\"../../data/house-prices/full.csv\")\n",
    "haouses.columns\n",
    "# haouses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d368cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "haouses['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "haouses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e85be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"SalePrice\"\n",
    "\n",
    "y = haouses[target_name]\n",
    "X = haouses.drop(columns=target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar información del dataset\n",
    "print(\"Características del dataset:\")\n",
    "print(f\"- Número de muestras: {X.shape[0]}\")\n",
    "print(f\"- Número de características: {X.shape[1]}\")\n",
    "print(f\"\\nNombres de las características:\\n{X.columns}\")\n",
    "print(f\"\\nDescripción de las características:\\n{X.info()}...\")\n",
    "\n",
    "# Ver primeras filas\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(X)\n",
    "categorical_columns = categorical_columns_selector(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f37a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge(alpha=1.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e95647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=40, test_size=0.2)\n",
    "\n",
    "cv_results = cross_validate(ridge_pipeline, X, y,\n",
    "                            cv=cv, scoring=\"neg_mean_absolute_error\",\n",
    "                            return_train_score=True, n_jobs=2)\n",
    "\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame()\n",
    "scores[[\"train error\", \"test error\"]] = -cv_results[\n",
    "    [\"train_score\", \"test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf269c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.plot.hist(bins=50, edgecolor=\"black\")\n",
    "plt.xlabel(\"Error absoluto medio (k$)\")\n",
    "_ = plt.title(\"Distribución de errores de entrenamiento y pruebas en la validación cruzada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bfc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "alpha_r = [0, 0.1, 0.5, 1, 5, 10, 15, 20]\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    ridge_pipeline, X, y, param_name=\"regressor__alpha\", param_range=alpha_r,\n",
    "    cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=2)\n",
    "\n",
    "train_errors, test_errors = -train_scores, -test_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trazamos los errores de entrenamiento y prueba (así como sus desviaciones).\n",
    "\n",
    "plt.plot(alpha_r, train_errors.mean(axis=1), label=\"Error de entrenamiento\")\n",
    "plt.plot(alpha_r, test_errors.mean(axis=1), label=\"Error de prueba\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Profundidad máxima del árbol de decisión (alpha_r)\")\n",
    "plt.ylabel(\"Error absoluto medio (k$)\")\n",
    "plt.title(\"Curva de validación para el árbol de decisión\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9fed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos repetir la misma gráfica, pero esta vez, añadiendo información para mostrar la desviación estándar de los errores.\n",
    "\n",
    "plt.errorbar(alpha_r, train_errors.mean(axis=1),\n",
    "             yerr=train_errors.std(axis=1), label='Error de entrenamiento')\n",
    "plt.errorbar(alpha_r, test_errors.mean(axis=1),\n",
    "             yerr=test_errors.std(axis=1), label='Error de prueba')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Profundidad máxima del árbol de decisión (alpha_r)\")\n",
    "plt.ylabel(\"Error absoluto medio (k$)\")\n",
    "plt.title(\"Curva de validación para el árbol de decisión\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
