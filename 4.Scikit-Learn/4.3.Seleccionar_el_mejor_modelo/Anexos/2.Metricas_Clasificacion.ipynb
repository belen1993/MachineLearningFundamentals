{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce255bb",
   "metadata": {},
   "source": [
    "# Métricas de Clasificación\n",
    "\n",
    "Los modelos de ML se basan en optimizar una función objetivo, buscando su mínimo o máximo.\n",
    "- Es importante comprender que esta función objetivo generalmente está desacopla de la métrica de evaluación que queremos optimizar en la práctica.\n",
    "- La función objetivo sirve como un proxy para la métrica de evaluación.\n",
    "\n",
    "En una configuración de clasificación, el vector `objetivo` es categórica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "blood_transfusion = pd.read_csv(\"../../../data/blood_transfusion.csv\")\n",
    "data = blood_transfusion.drop(columns=\"Class\")\n",
    "target = blood_transfusion[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos por verificar las clases presentes en el vector objetivo `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target.value_counts().plot.barh()\n",
    "plt.xlabel(\"Number of samples\")\n",
    "_ = plt.title(\"Number of samples per classes present\\n in the target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a86b3a",
   "metadata": {},
   "source": [
    "Podemos ver que el vector `target` contiene dos clases correspondientes a si un sujeto donó sangre.\n",
    "\n",
    "Usaremos un clasificador de regresión logística para predecir este resultado.\n",
    "\n",
    "Para centrarnos en la presentación de métricas, solo usaremos una sola división en lugar de validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, shuffle=True, random_state=0, test_size=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c10ef",
   "metadata": {},
   "source": [
    "Usaremos un clasificador de regresión logística como modelo base. \n",
    "\n",
    "Entrenaremos el modelo en el conjunto de trenes y luego usaremos el conjunto de prueba para calcular la métrica de clasificación diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d39c5c",
   "metadata": {},
   "source": [
    "## Predicciones del clasificador\n",
    "\n",
    "Antes de entrar en detalles sobre las métricas, recordaremos qué tipo de predicciones puede proporcionar un clasificador. \n",
    "\n",
    "Por esta razón, crearemos una muestra sintética para un nuevo donante potencial: donaron sangre dos veces en el pasado (1000 cm³ cada vez).La última vez fue hace 6 meses, y la primera vez se remonta a hace 20 meses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_donor = pd.DataFrame(\n",
    "    {\n",
    "        \"Recency\": [6],\n",
    "        \"Frequency\": [2],\n",
    "        \"Monetary\": [1000],\n",
    "        \"Time\": [20],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f7491",
   "metadata": {},
   "source": [
    "Podemos obtener la clase predicha por el clasificador llamando al método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict(new_donor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013894d",
   "metadata": {},
   "source": [
    "Con esta información, nuestro clasificador predice que es más probable que este sujeto sintético no vuelva a donar sangre.\n",
    "\n",
    "Sin embargo, no podemos verificar si la predicción es correcta (no conocemos el valor objetivo verdadero).\n",
    "\n",
    "- Ese es el propósito del conjunto de pruebas.\n",
    "\n",
    "Primero, predecimos si un sujeto dará sangre con la ayuda del clasificador entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted = classifier.predict(data_test)\n",
    "target_predicted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3a090",
   "metadata": {},
   "source": [
    "## Precisión como línea de base\n",
    "\n",
    "Ahora que tenemos estas predicciones, podemos compararlas con las verdaderas predicciones (a veces llamadas *ground-truth*) que no hemos usado hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test == target_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c0f99e",
   "metadata": {},
   "source": [
    "En la comparación anterior, un valor `True` significa que el valor predicho por nuestro clasificador es idéntico al valor real, mientras que un`False` significa que nuestro clasificador cometió un error.\n",
    "\n",
    "Una forma de obtener una tasa general que representa el rendimiento de generalización de nuestro clasificador sería calcular cuántas veces nuestro clasificador era correcto y dividirlo por el número de muestras en nuestro set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(target_test == target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee36a7",
   "metadata": {},
   "source": [
    "Esta medida se llama **precisión**.\n",
    "\n",
    "Aquí, nuestro clasificador es un 78% preciso para clasificar si un sujeto dará sangre.\n",
    "\n",
    "`scikit-learn` proporciona una función que calcula esta métrica en el módulo` sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(target_test, target_predicted)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d466c",
   "metadata": {},
   "source": [
    "`LogisticRegression` también tiene un método `score` (parte de la API estándar de Scikit-Learn), que calcula la puntuación de precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix and derived metrics\n",
    "\n",
    "The comparison that we did above and the accuracy that we calculated did not\n",
    "take into account the type of error our classifier was making. Accuracy is an\n",
    "aggregate of the errors made by the classifier. We may be interested in finer\n",
    "granularity - to know independently what the error is for each of the two\n",
    "following cases:\n",
    "\n",
    "- we predicted that a person will give blood but they did not;\n",
    "- we predicted that a person will not give blood but they did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05885b17",
   "metadata": {},
   "source": [
    "## Matriz de confusión y métricas derivadas\n",
    "\n",
    "La comparación que hicimos anteriormente y la precisión que calculamos no tuvo en cuenta el tipo de error que nuestro clasificador estaba cometiendo.\n",
    "\n",
    "La precisión es un agregado de los errores cometidos por el clasificador.\n",
    "\n",
    "Es posible que estemos interesados ​​en la granularidad más fina. Saber independientemente cuál es el error para cada uno de los dos casos siguientes:\n",
    "\n",
    "- Predijimos que una persona dará sangre pero no lo hizo;\n",
    "- Predijimos que una persona no dará sangre, pero lo hizo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "_ = ConfusionMatrixDisplay.from_estimator(classifier, data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08134560",
   "metadata": {},
   "source": [
    "The in-diagonal numbers are related to predictions that were correct while\n",
    "off-diagonal numbers are related to incorrect predictions\n",
    "(misclassifications). We now know the four types of correct and erroneous\n",
    "predictions:\n",
    "\n",
    "* the top left corner are true positives (TP) and corresponds to people who\n",
    "  gave blood and were predicted as such by the classifier;\n",
    "* the bottom right corner are true negatives (TN) and correspond to people who\n",
    "  did not give blood and were predicted as such by the classifier;\n",
    "* the top right corner are false negatives (FN) and correspond to people who\n",
    "  gave blood but were predicted to not have given blood;\n",
    "* the bottom left corner are false positives (FP) and correspond to people who\n",
    "  did not give blood but were predicted to have given blood.\n",
    "\n",
    "Once we have split this information, we can compute metrics to highlight the\n",
    "generalization performance of our classifier in a particular setting. For\n",
    "instance, we could be interested in the fraction of people who really gave\n",
    "blood when the classifier predicted so or the fraction of people predicted to\n",
    "have given blood out of the total population that actually did so.\n",
    "\n",
    "The former metric, known as the precision, is defined as `TP / (TP + FP)` and\n",
    "represents how likely the person actually gave blood when the classifier\n",
    "predicted that they did. The latter, known as the recall, defined as\n",
    "`TP / (TP + FN)` and assesses how well the classifier is able to correctly\n",
    "identify people who did give blood. We could, similarly to accuracy,\n",
    "manually compute these values, however scikit-learn provides functions to\n",
    "compute these statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44233665",
   "metadata": {},
   "source": [
    "Los números en diagonales están relacionados con predicciones que fueron correctas, mientras que los números fuera de la diagonal están relacionados con predicciones incorrectas (clasificaciones erróneas).Ahora conocemos los cuatro tipos de predicciones correctas y erróneas:\n",
    "\n",
    "* La esquina superior izquierda son verdaderos positivos (TP) y corresponde a personas que dieron sangre y fueron predicho como tal por el clasificador;\n",
    "* La esquina inferior derecha son verdaderos negativos (TN) y corresponden a personas que no dieron sangre y fueron predicho como tal por el clasificador;\n",
    "* La esquina superior derecha son falsos negativos (FN) y corresponden a personas que dieron sangre pero se predijo que no habían dado sangre;\n",
    "* La esquina inferior izquierda son falsos positivos (FP) y corresponden a personas que no dieron sangre pero se predijo que habían dado sangre.\n",
    "\n",
    "Una vez que hemos dividido esta información, podemos calcular métricas para resaltar el rendimiento de generalización de nuestro clasificador en un entorno particular.Por ejemplo, podríamos estar interesados ​​en la fracción de personas que realmente dieron sangre cuando el clasificador predijo eso o la fracción de las personas que predijeron haber dado sangre de la población total que realmente lo hizo.\n",
    "\n",
    "- La precisión, se define como `TP / (TP + FP)` y representa la probabilidad de que la persona realmente diera sangre cuando el clasificador predijo que sí.\n",
    "- Este último, conocido como el recall, definido como `TP / (TP + FN)` y evalúa qué tan bien el clasificador puede identificar correctamente a las personas que dieron sangre.\n",
    "\n",
    "Podríamos, de manera similar a la precisión, calcular manualmente estos valores, sin embargo, Scikit-Learn proporciona funciones para calcular estas estadísticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(target_test, target_predicted, pos_label=\"donated\")\n",
    "recall = recall_score(target_test, target_predicted, pos_label=\"donated\")\n",
    "\n",
    "print(f\"Precision score: {precision:.3f}\")\n",
    "print(f\"Recall score: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6504c8a3",
   "metadata": {},
   "source": [
    "Estos resultados están en línea con lo que se vio en la matriz de confusión.\n",
    "- Mirando la columna izquierda, más de la mitad de las predicciones \"donadas\" fueron correctas, lo que condujo a una precisión por encima de 0.5.\n",
    "- Sin embargo, nuestro clasificador equipó mal a muchas personas que dieron sangre como \"no donada\", lo que llevó a un retiro muy bajo de alrededor de 0.1.\n",
    "\n",
    "## El problema del desequilibrio de clases\n",
    "En esta etapa, podríamos hacernos una pregunta razonable: Si bien la precisión no se veía mala (es decir, 77%), la puntuación de recuperación es relativamente baja (es decir, 12%).\n",
    "- Como mencionamos, la precisión y el recall solo se centran en las muestras previstas para ser positivas, mientras que la precisión tiene en cuenta ambos.\n",
    "- Además, no observamos la relación de clases (etiquetas).Podríamos verificar esta relación en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.value_counts(normalize=True).plot.barh()\n",
    "plt.xlabel(\"Class frequency\")\n",
    "_ = plt.title(\"Class frequency in the training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7fe6a3",
   "metadata": {},
   "source": [
    "Observamos que la clase positiva, 'donated', comprende solo el 24% de las muestras. \n",
    "\n",
    "La buena precisión de nuestro clasificador se vincula a su capacidad para predecir correctamente la clase negativa `not donated` que puede o no ser relevante, dependiendo de la aplicación. \n",
    "\n",
    "Podemos ilustrar el problema usando un clasificador ficticio como línea de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier.fit(data_train, target_train)\n",
    "print(\n",
    "    \"Accuracy of the dummy classifier: \"\n",
    "    f\"{dummy_classifier.score(data_test, target_test):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d93f7ba",
   "metadata": {},
   "source": [
    "Con el clasificador ficticio, que siempre predice la clase negativa `not donated`, obtenemos un puntaje de precisión del 76%. \n",
    "- Por lo tanto, significa que este clasificador, sin aprender nada de los datos `data`, es capaz de predecir con tanta precisión como nuestro modelo de regresión logística.\n",
    "\n",
    "El problema ilustrado anteriormente también se conoce como el **problema de desequilibrio de clases**. \n",
    "- Cuando las clases están desequilibradas, la precisión no debe usarse. \n",
    "- En este caso, uno debe usar la precisión y el recall como se presentó anteriormente o la  *precisión equilibrada (balanced accuracy)* en lugar de la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy = balanced_accuracy_score(target_test, target_predicted)\n",
    "print(f\"Balanced accuracy: {balanced_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127aebe2",
   "metadata": {},
   "source": [
    "La *precisión equilibrada* es equivalente a la precisión en el contexto de clases equilibradas.Se define como el retiro promedio obtenido en cada clase.\n",
    "\n",
    "## Evaluación y diferentes umbrales de probabilidad\n",
    "\n",
    "Todas las estadísticas que presentamos ahora confían en `classifier.predict` que genera la etiqueta más probable.\n",
    "- No hemos hecho uso de la probabilidad asociada con esta predicción, lo que da la confianza del clasificador en esta predicción.\n",
    "- Por defecto, la predicción de un clasificador corresponde a un umbral de 0.5 probabilidad en un problema de clasificación binaria.\n",
    "\n",
    "Podemos verificar rápidamente esta relación con el clasificador que entrenamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_proba_predicted = pd.DataFrame(\n",
    "    classifier.predict_proba(data_test), columns=classifier.classes_\n",
    ")\n",
    "target_proba_predicted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted = classifier.predict(data_test)\n",
    "target_predicted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e372b72e",
   "metadata": {},
   "source": [
    "Dado que las probabilidades suman 1, podemos obtener la clase con la mayor probabilidad sin usar el umbral 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equivalence_pred_proba = (\n",
    "    target_proba_predicted.idxmax(axis=1).to_numpy() == target_predicted\n",
    ")\n",
    "np.all(equivalence_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd5b29",
   "metadata": {},
   "source": [
    "El umbral de decisión predeterminado (0.5) podría no ser el mejor umbral que conduce a un rendimiento de generalización óptimo de nuestro clasificador. \n",
    "- En este caso, uno puede variar el umbral de decisión y, por lo tanto, la predicción subyacente, y calcular las mismas estadísticas presentadas anteriormente. \n",
    "- Por lo general, los dos métricos retiran y la precisión se calculan y se representan en un gráfico. \n",
    "- Cada métrica trazada en un eje de gráfico y cada punto en el gráfico corresponde a un umbral de decisión específico. \n",
    "\n",
    "Comencemos calculando la curva de recolección de precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "disp = PrecisionRecallDisplay.from_estimator(\n",
    "    classifier, data_test, target_test, pos_label=\"donated\", marker=\"+\"\n",
    ")\n",
    "disp = PrecisionRecallDisplay.from_estimator(\n",
    "    dummy_classifier,\n",
    "    data_test,\n",
    "    target_test,\n",
    "    pos_label=\"donated\",\n",
    "    color=\"tab:orange\",\n",
    "    linestyle=\"--\",\n",
    "    ax=disp.ax_,\n",
    ")\n",
    "plt.xlabel(\"Recall (also known as TPR or sensitivity)\")\n",
    "plt.ylabel(\"Precision (also known as PPV)\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "_ = disp.ax_.set_title(\"Precision-recall curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2864ff",
   "metadata": {},
   "source": [
    "> Tip: Scikit-Learn devolverá una pantalla que contenga todo el elemento de trazado.En particular, las pantallas expondrán un eje matplotlib, llamado `ax_`, que se puede usar para agregar un nuevo elemento en el eje.Puede consultar la documentación para tener más información sobre las visualizaciones en Scikit-Learn\n",
    "\n",
    "En esta curva, cada cruz azul corresponde a un nivel de probabilidad que utilizamos como umbral de decisión.Podemos ver que, al variar este umbral de decisión, obtenemos diferentes valores de precisión frente a recuperación. \n",
    "\n",
    "Un clasificador perfecto tendría una precisión de 1 para todos los valores de recuperación.Una métrica que caracteriza la curva está vinculada al área bajo la curva (AUC) y se llama Precision promedio (AP).Con un clasificador ideal, la precisión promedio sería 1.\n",
    "\n",
    "Observe que el AP de un `DummyClassifier`, utilizado como línea de base para definir el nivel de posibilidad, coincide con el número de muestras en la clase positiva dividida por el número total de muestras (este número se llama prevalencia de la clase positiva)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence = (\n",
    "    target_test.value_counts()[\"donated\"] / target_test.value_counts().sum()\n",
    ")\n",
    "print(f\"Prevalence of the class 'donated': {prevalence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ef4d2",
   "metadata": {},
   "source": [
    "La métrica de precisión y recall se centra en la clase positiva, sin embargo, uno podría estar interesado en el compromiso entre discriminar con precisión la clase positiva y discriminar con precisión las clases negativas. \n",
    "- Las estadísticas utilizadas para esto son la *sensibilidad* y la *especificidad*. \n",
    "- La sensibilidad es solo otro nombre para el recall. \n",
    "- Sin embargo, la especificidad mide la proporción de muestras clasificadas correctamente en la clase negativa definida como: `TN / (TN + FP)`. \n",
    "- Similar a la curva de recolección de precisión, la sensibilidad y la especificidad generalmente se trazan como una curva llamada curva de características operativas del receptor (*ROC*).\n",
    "\n",
    "A continuación se muestra una curva:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "disp = RocCurveDisplay.from_estimator(\n",
    "    classifier, data_test, target_test, pos_label=\"donated\", marker=\"+\"\n",
    ")\n",
    "disp = RocCurveDisplay.from_estimator(\n",
    "    dummy_classifier,\n",
    "    data_test,\n",
    "    target_test,\n",
    "    pos_label=\"donated\",\n",
    "    color=\"tab:orange\",\n",
    "    linestyle=\"--\",\n",
    "    ax=disp.ax_,\n",
    ")\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\\n(also known as sensitivity or recall)\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "_ = disp.ax_.set_title(\"Receiver Operating Characteristic curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd9dc9",
   "metadata": {},
   "source": [
    "Esta curva se construyó utilizando el mismo principio que la curva de recuperación de precisión: variamos el umbral de probabilidad para determinar la predicción \"dura\" y calcular las métricas. \n",
    "- Al igual que con la curva de recuperación de precisión, podemos calcular el área bajo el ROC (ROC-AUC) para caracterizar el rendimiento de generalización de nuestro clasificador. \n",
    "- Sin embargo, es importante observar que el límite inferior del ROC-AUC es 0.5. \n",
    "- De hecho, mostramos el rendimiento de generalización de un clasificador ficticio (la línea naranja discontinua) para mostrar que incluso el peor rendimiento de generalización obtenido estará por encima de esta línea.\n",
    "\n",
    "En lugar de usar un clasificador ficticio, puede usar el parámetro `trapt_chance_level` disponible en las pantallas ROC y PR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(15, 7))\n",
    "\n",
    "PrecisionRecallDisplay.from_estimator(\n",
    "    classifier,\n",
    "    data_test,\n",
    "    target_test,\n",
    "    pos_label=\"donated\",\n",
    "    marker=\"+\",\n",
    "    plot_chance_level=True,\n",
    "    chance_level_kw={\"color\": \"tab:orange\", \"linestyle\": \"--\"},\n",
    "    ax=axs[0],\n",
    ")\n",
    "RocCurveDisplay.from_estimator(\n",
    "    classifier,\n",
    "    data_test,\n",
    "    target_test,\n",
    "    pos_label=\"donated\",\n",
    "    marker=\"+\",\n",
    "    plot_chance_level=True,\n",
    "    chance_level_kw={\"color\": \"tab:orange\", \"linestyle\": \"--\"},\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "_ = fig.suptitle(\"PR and ROC curves\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
