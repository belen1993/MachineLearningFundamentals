{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c95ba27a",
   "metadata": {},
   "source": [
    "# Efecto del tamaño de la muestra en validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2253ded",
   "metadata": {},
   "source": [
    "También es importante comprender cómo los diferentes errores están influenciados por el número de muestras disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd320ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "data, target = housing.data, housing.target\n",
    "target *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bbe9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb761b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6017a5d",
   "metadata": {},
   "source": [
    "## Curva de aprendizaje\n",
    "Podemos variar el número de muestras en el conjunto de entrenamiento y repetir el experimento. \n",
    "\n",
    "Los puntajes de entrenamiento y prueba se pueden trazar de manera similar a la curva de validación, pero en lugar de variar un hiperparámetro, variamos el número de muestras de entrenamiento.\n",
    "\n",
    "Esta curva se llama **Curva de aprendizaje**.\n",
    "- Proporciona información sobre el beneficio de agregar nuevas muestras de capacitación para mejorar el rendimiento de generalización de un modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac57640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculemos la curva de aprendizaje para un árbol de decisión y variemos la proporción del entrenamiento establecida del 10% al 100%.\n",
    "\n",
    "import numpy as np\n",
    "train_sizes = np.linspace(0.1, 1.0, num=5, endpoint=True)\n",
    "train_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usamos validación cruzada ShuffleSplit para evaluar nuestro modelo predictivo.\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=30, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listos para llevar a cabo el experimento:\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "results = learning_curve(\n",
    "    regressor, data, target, train_sizes=train_sizes, cv=cv, scoring='neg_mean_absolute_error', n_jobs=2\n",
    "    )\n",
    "\n",
    "train_size, train_scores, test_scores = results[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73af382",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors, test_errors = -train_scores, -test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a23695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar la curva.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.errorbar(train_size, train_errors.mean(axis=1),\n",
    "             yerr=train_errors.std(axis=1), label=\"Error de entrenamiento\")\n",
    "plt.errorbar(train_size, test_errors.mean(axis=1),\n",
    "             yerr=test_errors.std(axis=1), label=\"Error de prueba\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Número de muestras en el conjunto de entrenamiento\")\n",
    "plt.ylabel(\"Error absoluto medio (k $)\")\n",
    "plt.title(\"Curva de aprendizaje para el árbol de decisión\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e499f8",
   "metadata": {},
   "source": [
    "- Observando solo el **error de entrenamiento**, vemos que tenemos un error de 0 k$.\n",
    "    - Significa que el modelo entrenado está claramente sobreajustado los datos.\n",
    "\n",
    "- Observando solo el **error de prueba**, observamos que cuantas más muestras se agregan al conjunto de entrenamiento, menor será el error de prueba.\n",
    "    - Además, estamos buscando la meseta del error de prueba para el cual ya no hay beneficio de agregar muestras o evaluar la posible ganancia de agregar más muestras al conjunto de capacitación.\n",
    "    - Si logramos una meseta y agregar nuevas muestras en el conjunto de entrenamiento no reduce el error de prueba, es posible que hayamos alcanzado la **tasa de error Bayes** utilizando el modelo disponible.\n",
    "        - Usar de un modelo más complejo podría ser la única posibilidad de reducir aún más el error de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2427d",
   "metadata": {},
   "source": [
    "## **Conclusiones**\n",
    "\n",
    "- Modelo **sobreajusta**:\n",
    "    - El número de muestras en el \"conjunto de entrenamiento\" es demasiado pequeño\n",
    "    - *El error de prueba es mucho más grande que el error de entrenamiento*\n",
    "\n",
    "- Modelo **subajusta**:\n",
    "    - Los modelos no pueden capturar la forma del \"conjunto de entrenamiento\"\n",
    "    - *Incluso el error de entrenamiento es grande*\n",
    "\n",
    "**Diferentes familias de modelos** = Diferente complejidad & sesgo inductivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d184481",
   "metadata": {},
   "source": [
    "## **Ejercicio**\n",
    "\n",
    "Para el dataset \"house-prices/full.csv\" y usando Ridge: \n",
    "\n",
    "- Encuentra la meseta del error de prueba, donde ya no hay beneficios de añadir más datos al entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a352b273",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "haouses = pd.read_csv(\"../../data/house-prices/full.csv\")\n",
    "haouses.columns\n",
    "# haouses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a969e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "haouses['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "haouses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f613f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"SalePrice\"\n",
    "\n",
    "y = haouses[target_name]\n",
    "X = haouses.drop(columns=target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186cc90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar información del dataset\n",
    "print(\"Características del dataset:\")\n",
    "print(f\"- Número de muestras: {X.shape[0]}\")\n",
    "print(f\"- Número de características: {X.shape[1]}\")\n",
    "print(f\"\\nNombres de las características:\\n{X.columns}\")\n",
    "print(f\"\\nDescripción de las características:\\n{X.info()}...\")\n",
    "\n",
    "# Ver primeras filas\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ca26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(X)\n",
    "categorical_columns = categorical_columns_selector(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18250cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a64c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e197b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebca7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge(alpha=12))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba20f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=40, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0446d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_sizes = np.linspace(0.1, 1.0, num=5, endpoint=True)\n",
    "train_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "results = learning_curve(\n",
    "    ridge_pipeline, X, y, train_sizes=train_sizes, cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=2)\n",
    "\n",
    "\n",
    "train_size, train_scores, test_scores = results[:3]\n",
    "\n",
    "# Convertir el negativo de los puntajes de error\n",
    "train_errors, test_errors = -train_scores, -test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar la curva.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.errorbar(train_size, train_errors.mean(axis=1),\n",
    "             yerr=train_errors.std(axis=1), label=\"Error de entrenamiento\")\n",
    "plt.errorbar(train_size, test_errors.mean(axis=1),\n",
    "             yerr=test_errors.std(axis=1), label=\"Error de prueba\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Número de muestras en el conjunto de entrenamiento\")\n",
    "plt.ylabel(\"Error absoluto medio (k $)\")\n",
    "plt.title(\"Curva de aprendizaje para el árbol de decisión\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
