{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c95ba27a",
   "metadata": {},
   "source": [
    "# Efecto del tamaño de la muestra en validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2253ded",
   "metadata": {},
   "source": [
    "También es importante comprender cómo los diferentes errores están influenciados por el número de muestras disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd320ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "data, target = housing.data, housing.target\n",
    "target *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb761b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6017a5d",
   "metadata": {},
   "source": [
    "## Curva de aprendizaje\n",
    "Podemos variar el número de muestras en el conjunto de entrenamiento y repetir el experimento. \n",
    "\n",
    "Los puntajes de entrenamiento y prueba se pueden trazar de manera similar a la curva de validación, pero en lugar de variar un hiperparámetro, variamos el número de muestras de entrenamiento.\n",
    "\n",
    "Esta curva se llama **Curva de aprendizaje**.\n",
    "- Proporciona información sobre el beneficio de agregar nuevas muestras de capacitación para mejorar el rendimiento de generalización de un modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac57640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculemos la curva de aprendizaje para un árbol de decisión y variemos la proporción del entrenamiento establecida del 10% al 100%.\n",
    "\n",
    "import numpy as np\n",
    "train_sizes = np.linspace(0.1, 1.0, num=5, endpoint=True)\n",
    "train_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usamos validación cruzada ShuffleSplit para evaluar nuestro modelo predictivo.\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=30, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listos para llevar a cabo el experimento:\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "results = learning_curve(\n",
    "    regressor, data, target, train_sizes=train_sizes, cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=2)\n",
    "train_size, train_scores, test_scores = results[:3]\n",
    "\n",
    "# Convertir el negativo de los puntajes de error\n",
    "train_errors, test_errors = -train_scores, -test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a23695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar la curva.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.errorbar(train_size, train_errors.mean(axis=1),\n",
    "             yerr=train_errors.std(axis=1), label=\"Error de entrenamiento\")\n",
    "plt.errorbar(train_size, test_errors.mean(axis=1),\n",
    "             yerr=test_errors.std(axis=1), label=\"Error de prueba\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Número de muestras en el conjunto de entrenamiento\")\n",
    "plt.ylabel(\"Error absoluto medio (k $)\")\n",
    "plt.title(\"Curva de aprendizaje para el árbol de decisión\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e499f8",
   "metadata": {},
   "source": [
    "- Observando solo el **error de entrenamiento**, vemos que tenemos un error de 0 k$.\n",
    "    - Significa que el modelo entrenado está claramente sobreajustado los datos.\n",
    "\n",
    "- Observando solo el **error de prueba**, observamos que cuantas más muestras se agregan al conjunto de entrenamiento, menor será el error de prueba.\n",
    "    - Además, estamos buscando la meseta del error de prueba para el cual ya no hay beneficio de agregar muestras o evaluar la posible ganancia de agregar más muestras al conjunto de capacitación.\n",
    "    - Si logramos una meseta y agregar nuevas muestras en el conjunto de entrenamiento no reduce el error de prueba, es posible que hayamos alcanzado la **tasa de error Bayes** utilizando el modelo disponible.\n",
    "        - Usar de un modelo más complejo podría ser la única posibilidad de reducir aún más el error de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2427d",
   "metadata": {},
   "source": [
    "## **Conclusiones**\n",
    "\n",
    "- Modelo **sobreajusta**:\n",
    "    - El número de muestras en el \"conjunto de entrenamiento\" es demasiado pequeño\n",
    "    - *El error de prueba es mucho más grande que el error de entrenamiento*\n",
    "\n",
    "- Modelo **subajusta**:\n",
    "    - Los modelos no pueden capturar la forma del \"conjunto de entrenamiento\"\n",
    "    - *Incluso el error de entrenamiento es grande*\n",
    "\n",
    "**Diferentes familias de modelos** = Diferente complejidad & sesgo inductivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d184481",
   "metadata": {},
   "source": [
    "## **Ejercicio**\n",
    "\n",
    "Para el dataset \"house-prices/full.csv\" y usando Ridge: \n",
    "\n",
    "- Encuentra la meseta del error de prueba, donde ya no hay beneficios de añadir más datos al entrenamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
