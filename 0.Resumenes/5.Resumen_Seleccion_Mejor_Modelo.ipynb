{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df8a1529",
   "metadata": {},
   "source": [
    "# Resumen Selección mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c1405",
   "metadata": {},
   "source": [
    "## Validación cruzada\n",
    "\n",
    "Dado un Estimador or Pipeline: *`model`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550aef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Definimos el tipo de validación cruzada\n",
    "cv = ShuffleSplit(n_splits=40, test_size=0.3, random_state=0)\n",
    "\n",
    "# Aplicamos la validación cruzada\n",
    "cv_results = cross_validate( model, data, target, cv=cv, scoring=\"neg_mean_absolute_error\", return_estimator=True)\n",
    "\n",
    "# transformamos los resultados en un DataFrame para procesarlo mejor\n",
    "cv_results_df = pd.DataFrame(cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efebaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener los errores de entrenamiento y test invirtiendo los negativos\n",
    "scores[[\"train error\", \"test error\"]] = -cv_results[[\"train_score\", \"test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficamos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores.plot.hist(bins=50, edgecolor=\"black\")\n",
    "plt.xlabel(\"Error absoluto medio (k$)\")\n",
    "_ = plt.title(\"Distribución de errores de entrenamiento y pruebas en la validación cruzada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c23f6e",
   "metadata": {},
   "source": [
    "## Curva de validación\n",
    "\n",
    "**Iteramos sobre un hiperparámetro para ver cómo influye en las mátricas**\n",
    "\n",
    "- Tener en cuenta que el nombre del hiperparámetro es:\n",
    "    - Si el modelo es un estimador, el nombre tal cual. e.g. `max_depth`\n",
    "    - Si es un pipeline, `<nombre_del_step>__<nombre_hiperparámentro>`. e,g, `regressor__max_depth`\n",
    "\n",
    "- `cv` puede ser un número (K-Fold) o un objeto (e.g. Shuffle-Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee082a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "max_depth = [1, 5, 10, 15, 20, 25]\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    model, data, target, param_name=\"regressor__max_depth\", param_range=max_depth,\n",
    "    cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=2)\n",
    "\n",
    "train_errors, test_errors = -train_scores, -test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7710dc",
   "metadata": {},
   "source": [
    "### Graficamos los errores de entrenamiento y prueba (así como sus desviaciones).\n",
    "\n",
    "Buscamos el menor error de prueba, con el menor error de entrenamiento, pero sin sobreajustar (mayor que 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los errores de entrenamiento y prueba\n",
    "\n",
    "plt.plot(max_depth, train_errors.mean(axis=1), label=\"Error de entrenamiento\")\n",
    "plt.plot(max_depth, test_errors.mean(axis=1), label=\"Error de prueba\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Profundidad máxima del árbol de decisión (max_depth)\")\n",
    "plt.ylabel(\"Error absoluto medio (k$)\")\n",
    "plt.title(\"Curva de validación para el árbol de decisión\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misma gráfica,añadiendo información para mostrar la desviación estándar de los errores.\n",
    "\n",
    "plt.errorbar(max_depth, train_errors.mean(axis=1),\n",
    "             yerr=train_errors.std(axis=1), label='Error de entrenamiento')\n",
    "plt.errorbar(max_depth, test_errors.mean(axis=1),\n",
    "             yerr=test_errors.std(axis=1), label='Error de prueba')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Profundidad máxima del árbol de decisión (max_depth)\")\n",
    "plt.ylabel(\"Error absoluto medio (k$)\")\n",
    "plt.title(\"Curva de validación para el árbol de decisión\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da74da9",
   "metadata": {},
   "source": [
    "## Curva de aprendizaje\n",
    "\n",
    "**Iteramos sobre el volumen de datos para ver cómo influye en las métricas y si converge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes = np.linspace(0.1, 1.0, num=5, endpoint=True)\n",
    "\n",
    "\n",
    "results = learning_curve(model, data, target, train_sizes=train_sizes, cv=cv, scoring='neg_mean_absolute_error', n_jobs=2)\n",
    "\n",
    "train_size, train_scores, test_scores = results[:3]\n",
    "\n",
    "train_errors, test_errors = -train_scores, -test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5491fb6",
   "metadata": {},
   "source": [
    "### Graficamos los errores de entrenamiento y prueba (así como sus desviaciones).\n",
    "\n",
    "- Buscamos el menor error de prueba, con el menor error de entrenamiento, pero sin sobreajustar (mayor que 0).\n",
    "- Verificamos si se resducen o mantienen conforme incrementamos las muestars (convergen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92890c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar la curva.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.errorbar(train_size, train_errors.mean(axis=1), yerr=train_errors.std(axis=1), label=\"Error de entrenamiento\")\n",
    "plt.errorbar(train_size, test_errors.mean(axis=1), yerr=test_errors.std(axis=1), label=\"Error de prueba\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Número de muestras en el conjunto de entrenamiento\")\n",
    "plt.ylabel(\"Error absoluto medio (k $)\")\n",
    "plt.title(\"Curva de aprendizaje para el árbol de decisión\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
