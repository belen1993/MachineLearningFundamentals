{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df8a1529",
   "metadata": {},
   "source": [
    "# Resumen Selección Candidatos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5287e2",
   "metadata": {},
   "source": [
    "## Selección de Algoritmos de Machine Learning según Casos de Uso\n",
    "\n",
    "| Caso de Uso | Algoritmos Candidatos (orden sugerido) | Orden de Prueba |\n",
    "|------------|----------------------|----------------|\n",
    "| **Regresión lineal simple** | `LinearRegression`, `Ridge`, `Lasso`, `ElasticNet` | 1. `LinearRegression` → 2. `Ridge` → 3. `Lasso` → 4. `ElasticNet` |\n",
    "| **Regresión con datos no lineales** | `DecisionTreeRegressor`, `RandomForestRegressor`, `GradientBoostingRegressor`, `SVR` | 1. `DecisionTreeRegressor` → 2. `RandomForestRegressor` → 3. `GradientBoostingRegressor` → 4. `SVR` |\n",
    "| **Regresión con muchas variables correlacionadas** | `Ridge`, `Lasso`, `ElasticNet`, `GradientBoostingRegressor` | 1. `Lasso` → 2. `Ridge` → 3. `ElasticNet` → 4. `GradientBoostingRegressor` |\n",
    "| **Clasificación binaria con datos linealmente separables** | `LogisticRegression`, `SVC (kernel='linear')`, `SGDClassifier` | 1. `LogisticRegression` → 2. `SVC (kernel='linear')` → 3. `SGDClassifier` |\n",
    "| **Clasificación binaria con datos no lineales** | `SVC (kernel='rbf')`, `RandomForestClassifier`, `GradientBoostingClassifier`, `KNeighborsClassifier` | 1. `SVC (kernel='rbf')` → 2. `RandomForestClassifier` → 3. `GradientBoostingClassifier` → 4. `KNeighborsClassifier` |\n",
    "| **Clasificación multiclase** | `RandomForestClassifier`, `GradientBoostingClassifier`, `SVC`, `KNeighborsClassifier`, `Naive Bayes` | 1. `RandomForestClassifier` → 2. `GradientBoostingClassifier` → 3. `SVC` → 4. `KNeighborsClassifier` → 5. `Naive Bayes` |\n",
    "| **Clasificación con datos desbalanceados** | `RandomForestClassifier`, `GradientBoostingClassifier`, `BalancedRandomForestClassifier`, `SMOTE + otro modelo` | 1. `BalancedRandomForestClassifier` → 2. `GradientBoostingClassifier` → 3. `RandomForestClassifier` → 4. `SMOTE + otro modelo` |\n",
    "| **Clasificación de texto** | `MultinomialNB`, `LogisticRegression`, `RandomForestClassifier` | 1. `MultinomialNB` → 2. `LogisticRegression` → 3. `RandomForestClassifier` |\n",
    "| **Clasificación de imágenes** | `SVC (kernel='rbf')`, `RandomForestClassifier`, `GradientBoostingClassifier`, `Red Neuronal (MLPClassifier)` | 1. `SVC (kernel='rbf')` → 2. `RandomForestClassifier` → 3. `GradientBoostingClassifier` → 4. `MLPClassifier` |\n",
    "| **Clustering con número conocido de grupos** | `KMeans`, `GaussianMixture`, `AgglomerativeClustering` | 1. `KMeans` → 2. `GaussianMixture` → 3. `AgglomerativeClustering` |\n",
    "| **Clustering con número desconocido de grupos** | `DBSCAN`, `MeanShift`, `AgglomerativeClustering` | 1. `DBSCAN` → 2. `MeanShift` → 3. `AgglomerativeClustering` |\n",
    "| **Detección de anomalías** | `IsolationForest`, `LocalOutlierFactor`, `OneClassSVM` | 1. `IsolationForest` → 2. `LocalOutlierFactor` → 3. `OneClassSVM` |\n",
    "| **Reducción de dimensionalidad** | `PCA`, `TruncatedSVD`, `t-SNE`, `UMAP` | 1. `PCA` → 2. `TruncatedSVD` → 3. `t-SNE` → 4. `UMAP` |\n",
    "\n",
    "\n",
    "**Cómo usar esta tabla**\n",
    "1. Identifica tu caso de uso en la primera columna.\n",
    "2. Prueba los algoritmos en el orden sugerido de izquierda a derecha.\n",
    "3. Ajusta hiperparámetros según los resultados para mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0fc623",
   "metadata": {},
   "source": [
    "## Condiciones de Uso de Algoritmos de Machine Learning en Scikit-Learn\n",
    "\n",
    "### **Regresión**\n",
    "| Algoritmo | Cuándo Usarlo | Condiciones de Uso |\n",
    "|-----------|-------------|--------------------|\n",
    "| **Regresión Lineal** (`LinearRegression`) | Cuando la relación entre variables es lineal. | Supone independencia de las variables predictoras, sin multicolinealidad significativa. |\n",
    "| **Regresión Ridge** (`Ridge`) | Cuando hay multicolinealidad en los datos. | Agrega regularización L2 para evitar sobreajuste. |\n",
    "| **Regresión Lasso** (`Lasso`) | Cuando se busca selección de características. | Usa regularización L1 para reducir coeficientes a cero, eliminando características irrelevantes. |\n",
    "| **ElasticNet** (`ElasticNet`) | Cuando se necesita un balance entre Ridge y Lasso. | Mezcla L1 y L2, útil cuando hay muchas variables correlacionadas. |\n",
    "| **Support Vector Regression (SVR)** (`SVR`) | Para problemas de regresión con datos no lineales. | Sensible a la escala de los datos, requiere normalización. |\n",
    "| **Random Forest Regressor** (`RandomForestRegressor`) | Cuando se necesita manejar relaciones no lineales y reducir el sobreajuste. | Adecuado para conjuntos de datos grandes y variables con relaciones complejas. |\n",
    "| **Gradient Boosting Regressor** (`GradientBoostingRegressor`) | Para obtener predicciones de alta precisión en problemas de regresión. | Puede ser propenso al sobreajuste si no se ajusta correctamente. |\n",
    "\n",
    "### **Clasificación**\n",
    "| Algoritmo | Cuándo Usarlo | Condiciones de Uso |\n",
    "|-----------|-------------|--------------------|\n",
    "| **Regresión Logística** (`LogisticRegression`) | Para clasificación binaria o multiclase cuando los datos son linealmente separables. | Supone independencia de predictores, sensible a valores atípicos. |\n",
    "| **K-Nearest Neighbors (KNN)** (`KNeighborsClassifier`) | Cuando se necesita un modelo simple y sin supuestos fuertes. | No es eficiente en grandes volúmenes de datos, sensible a la escala de las variables. |\n",
    "| **Support Vector Machine (SVM)** (`SVC`) | Para clasificación en espacios con dimensiones altas. | Sensible a la escala de los datos, puede ser costoso en grandes volúmenes. |\n",
    "| **Árbol de Decisión** (`DecisionTreeClassifier`) | Cuando se necesita un modelo interpretable y fácil de visualizar. | Propenso al sobreajuste si no se poda correctamente. |\n",
    "| **Random Forest** (`RandomForestClassifier`) | Para problemas con muchas variables y cuando se necesita robustez. | Reduce el sobreajuste de los árboles de decisión individuales. |\n",
    "| **Gradient Boosting** (`GradientBoostingClassifier`) | Para mejorar el rendimiento en problemas complejos de clasificación. | Sensible a hiperparámetros, puede ser más lento que Random Forest. |\n",
    "| **Naive Bayes** (`GaussianNB`, `MultinomialNB`) | Para clasificación de texto y datos categóricos. | Supone independencia entre las características, no siempre realista. |\n",
    "\n",
    "### **Agrupamiento (Clustering)**\n",
    "| Algoritmo | Cuándo Usarlo | Condiciones de Uso |\n",
    "|-----------|-------------|--------------------|\n",
    "| **K-Means** (`KMeans`) | Cuando se conoce el número de grupos en los datos. | Sensible a valores atípicos, requiere elección de `k`. |\n",
    "| **DBSCAN** (`DBSCAN`) | Para datos con densidad variable y detección de outliers. | No requiere definir el número de clusters, pero depende de `eps` y `min_samples`. |\n",
    "| **Mean Shift** (`MeanShift`) | Cuando no se conoce el número de clusters de antemano. | Automáticamente detecta el número de clusters, pero es computacionalmente costoso. |\n",
    "\n",
    "### **Reducción de Dimensionalidad**\n",
    "| Algoritmo | Cuándo Usarlo | Condiciones de Uso |\n",
    "|-----------|-------------|--------------------|\n",
    "| **PCA** (`PCA`) | Para reducir la dimensionalidad preservando la varianza de los datos. | Supone que los componentes principales explican la variabilidad más relevante. |\n",
    "| **t-SNE** (`TSNE`) | Para visualizar datos en espacios de alta dimensión. | Requiere ajuste fino de hiperparámetros (`perplexity` y `learning_rate`). |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a0926",
   "metadata": {},
   "source": [
    "## Umbrales de métricas\n",
    "\n",
    "Umbrales para interpretar las métricas en función del contexto del problema y la relación con el target:\n",
    "\n",
    "| **Métrica**       | **Estadística del Target a Evaluar** | **Valor Excelente**                                                                 | **Valor Bueno**                                                                 | **Valor Malo**                                                                 | **Valor Pésimo**                                                              |\n",
    "|--------------------|---------------------------------------|-------------------------------------------------------------------------------------|---------------------------------------------------------------------------------|--------------------------------------------------------------------------------|-------------------------------------------------------------------------------|\n",
    "| **MSE (Mean Squared Error)** | Varianza del Target                  | MSE < 25% de la varianza del target                                                 | MSE entre 25%-50% de la varianza del target                                     | MSE entre 50%-75% de la varianza del target                                    | MSE > 75% de la varianza del target                                           |\n",
    "| **MAE (Mean Absolute Error)** | Media del Target                     | MAE < 5% de la media del target                                                     | MAE entre 5%-10% de la media del target                                         | MAE entre 10%-20% de la media del target                                       | MAE > 20% de la media del target                                              |\n",
    "| **R² (Coeficiente de Determinación)** | Varianza del Target                  | R² > 0.9 (explica más del 90% de la varianza)                                       | R² entre 0.7-0.9 (explica entre 70%-90% de la varianza)                         | R² entre 0.3-0.7 (explica entre 30%-70% de la varianza)                        | R² < 0.3 (explica menos del 30% de la varianza)                               |\n",
    "| **Accuracy**       | Proporción de Clases Mayoritarias     | Accuracy > 0.9 (en problemas balanceados)                                           | Accuracy entre 0.8-0.9                                                          | Accuracy entre 0.6-0.8                                                         | Accuracy < 0.6                                                                |\n",
    "| **F1-Score**       | Distribución de Clases                | F1-Score > 0.9 (excelente equilibrio entre precisión y recall)                      | F1-Score entre 0.7-0.9                                                          | F1-Score entre 0.5-0.7                                                         | F1-Score < 0.5                                                                |\n",
    "| **Precision**      | Proporción de Clases Positivas        | Precision > 0.9 (muy baja tasa de falsos positivos)                                 | Precision entre 0.8-0.9                                                         | Precision entre 0.5-0.8                                                        | Precision < 0.5                                                               |\n",
    "| **Recall**         | Proporción de Clases Positivas        | Recall > 0.9 (muy baja tasa de falsos negativos)                                    | Recall entre 0.7-0.9                                                            | Recall entre 0.5-0.7                                                           | Recall < 0.5                                                                  |\n",
    "| **ROC-AUC**        | Distribución de Probabilidades        | ROC-AUC > 0.9 (excelente poder discriminativo)                                      | ROC-AUC entre 0.8-0.9                                                           | ROC-AUC entre 0.6-0.8                                                          | ROC-AUC < 0.6                                                                 |\n",
    "| **Log Loss**       | Entropía del Target                   | Log Loss < 0.1 (probabilidades extremadamente bien calibradas)                      | Log Loss entre 0.1-0.5                                                          | Log Loss entre 0.5-1.0                                                         | Log Loss > 1.0                                                                |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
